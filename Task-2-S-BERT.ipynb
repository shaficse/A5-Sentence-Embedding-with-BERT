{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Sentence-BERT](https://arxiv.org/pdf/1908.10084.pdf)\n",
    "\n",
    "[Reference Code](https://www.pinecone.io/learn/series/nlp/train-sentence-transformers-softmax/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imported Libraries\n",
    "\n",
    "The code imports essential Python libraries for mathematical operations (`math`), regular expressions (`re`), random number generation (`random`), numerical computing (`numpy`), and deep learning with PyTorch (`torch`). Specifically, PyTorch modules for neural networks (`torch.nn`) and optimization (`torch.optim`) are imported. These imports lay the groundwork for various computational tasks, including data manipulation, model building, and optimization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import re\n",
    "from   random import *\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Features Summary\n",
    "\n",
    "The provided code snippet loads two datasets using the Hugging Face `datasets` library: SNLI (Stanford Natural Language Inference) and MNLI (Multi-Genre Natural Language Inference). Here's a summary of the features for both datasets:\n",
    "\n",
    "- **SNLI Dataset Features**:\n",
    "  - The SNLI dataset is loaded using `datasets.load_dataset('snli')`.\n",
    "  - The dataset features include:\n",
    "    - `premise`: Textual premise for the sentence pair.\n",
    "    - `hypothesis`: Textual hypothesis for the sentence pair.\n",
    "    - `label`: Ground truth label indicating the relationship between the premise and hypothesis (e.g., entailment, contradiction, or neutral).\n",
    "\n",
    "- **MNLI Dataset Features**:\n",
    "  - The MNLI dataset is loaded using `datasets.load_dataset('glue', 'mnli')`.\n",
    "  - The dataset features for the 'train' split include:\n",
    "    - `premise`: Textual premise for the sentence pair.\n",
    "    - `hypothesis`: Textual hypothesis for the sentence pair.\n",
    "    - `label`: Ground truth label indicating the relationship between the premise and hypothesis, similar to SNLI.\n",
    "\n",
    "These features provide essential information about the structure of the datasets, which includes textual data for premise and hypothesis, along with corresponding labels for inference tasks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shafisourov/anaconda3/envs/nlu/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None),\n",
       "  'idx': Value(dtype='int32', id=None)},\n",
       " {'premise': Value(dtype='string', id=None),\n",
       "  'hypothesis': Value(dtype='string', id=None),\n",
       "  'label': ClassLabel(names=['entailment', 'neutral', 'contradiction'], id=None)})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "snli = datasets.load_dataset('snli')\n",
    "mnli = datasets.load_dataset('glue', 'mnli')\n",
    "mnli['train'].features, snli['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of datasets to remove 'idx' column from\n",
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'idx' column from each dataset\n",
    "for column_names in mnli.column_names.keys():\n",
    "    mnli[column_names] = mnli[column_names].remove_columns('idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation_matched', 'validation_mismatched', 'test_matched', 'test_mismatched'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnli.column_names.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([-1,  0,  1,  2]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there are -1 values in the label feature, these are where no class could be decided so we remove\n",
    "snli = snli.filter(\n",
    "    lambda x: 0 if x['label'] == -1 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnli = mnli.filter(\n",
    "    lambda x: 0 if x['label'] == -1 else 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2]), array([0, 1, 2]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(mnli['train']['label']), np.unique(snli['train']['label'])\n",
    "#snli also have -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Dataset Summary\n",
    "\n",
    "The provided code snippet merges two DatasetDict objects, `snli` and `mnli`, into a single DatasetDict object named `raw_dataset`. Here's a summary of the merged dataset:\n",
    "\n",
    "- **Train Dataset**:\n",
    "  - Combined train data from SNLI and MNLI.\n",
    "  - The dataset has been shuffled.\n",
    "  - Selected a subset of 85 samples for training.\n",
    "\n",
    "- **Test Dataset**:\n",
    "  - Combined test data from SNLI and MNLI mismatched test set.\n",
    "  - The dataset has been shuffled.\n",
    "  - Selected a subset of 15 samples for testing.\n",
    "\n",
    "- **Validation Dataset**:\n",
    "  - Combined validation data from SNLI and MNLI mismatched validation set.\n",
    "  - The dataset has been shuffled.\n",
    "  - Selected a subset of 15 samples for validation.\n",
    "\n",
    "This merged dataset provides a comprehensive collection of training, testing, and validation samples from both SNLI and MNLI datasets, allowing for a more diverse and robust evaluation of natural language inference models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 85\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 15\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['premise', 'hypothesis', 'label'],\n",
       "        num_rows: 15\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming you have your two DatasetDict objects named snli and mnli\n",
    "from datasets import DatasetDict\n",
    "# Merge the two DatasetDict objects\n",
    "raw_dataset = DatasetDict({\n",
    "    'train': datasets.concatenate_datasets([snli['train'], mnli['train']]).shuffle(seed=55).select(list(range(85))),\n",
    "    'test': datasets.concatenate_datasets([snli['test'], mnli['test_mismatched']]).shuffle(seed=55).select(list(range(15))),\n",
    "    'validation': datasets.concatenate_datasets([snli['validation'], mnli['validation_mismatched']]).shuffle(seed=55).select(list(range(15)))\n",
    "})\n",
    "# Now, merged_dataset_dict contains the combined datasets from snli and mnli\n",
    "raw_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Vocabulary Loading\n",
    "\n",
    "The provided code snippet demonstrates the tokenization process using the `basic_english` tokenizer from `torchtext` and loading a vocabulary from a saved file. Here's a summary:\n",
    "\n",
    "- **Tokenizer Loading**:\n",
    "  - Utilizes the `get_tokenizer` function from `torchtext.data.utils` to load the `basic_english` tokenizer.\n",
    "  - This tokenizer is commonly used for tokenizing text data in English based on basic word boundaries.\n",
    "\n",
    "- **Vocabulary Loading**:\n",
    "  - Loads a vocabulary from a saved file named `'vocab.pth'`.\n",
    "  - The vocabulary is loaded into the variable `vocab`.\n",
    "  - The vocabulary likely contains mappings from tokens to their corresponding integer indices and vice versa, facilitating tokenization and numerical encoding of text data.\n",
    "\n",
    "These steps are crucial for preprocessing text data before feeding it into machine learning models, especially for tasks like natural language processing and understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "# Load the 'basic_english' tokenizer\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "vocab = torch.load('./model/vocab.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of '[PAD]': 0\n",
      "Index of '[CLS]': 1\n",
      "Index of '[SEP]': 2\n",
      "Index of '[MASK]': 3\n",
      "Index of '[UNK]': 4\n",
      "Index of 'the': 4\n",
      "Index of 'of': 4\n",
      "Index of 'and': 4\n"
     ]
    }
   ],
   "source": [
    "tokens_to_check = ['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]', 'the', 'of', 'and']\n",
    "for token in tokens_to_check:\n",
    "    print(f\"Index of '{token}': {vocab[token]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world how are you doing today let's explore  regex\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "sent = \"Hello, world! How are you doing today? Let's explore - regex.\"\n",
    "cleaned_sent = re.sub(\"[.,!?\\\\-]\", '', sent.lower())\n",
    "\n",
    "print(cleaned_sent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization and Padding\n",
    "\n",
    "The provided code snippet showcases tokenization and padding of sentences using a specified tokenizer and vocabulary. Here's a summary:\n",
    "\n",
    "- **Max Sequence Length**:\n",
    "  - `max_seq_length` is set to `512`, defining the maximum length for tokenized sequences.\n",
    "\n",
    "- **Tokenization and Padding Functions**:\n",
    "  - `tokenize_and_pad(sentences, tokenizer, vocab, max_length=512)`: \n",
    "    - Tokenizes the input sentences using the specified `tokenizer`, removes punctuation marks, and converts text to lowercase.\n",
    "    - Converts tokens to IDs based on the provided `vocab`.\n",
    "    - Adds special tokens (`[CLS]` and `[SEP]`) at the beginning and end of each tokenized sequence, respectively.\n",
    "    - Applies padding to ensure all sequences have the same length (`max_length`).\n",
    "    \n",
    "- **Preprocess Function** (`preprocess_function(examples)`):\n",
    "  - Tokenizes and pads both premise and hypothesis sentences using `tokenize_and_pad`.\n",
    "  - Extracts labels from the examples.\n",
    "\n",
    "- **Mapping Preprocessing Function**:\n",
    "  - Applies the `preprocess_function` to the entire dataset in a batched manner using the `map` method.\n",
    "  - Returns tokenized datasets containing processed input IDs, attention masks, and labels.\n",
    "\n",
    "- **Dataset Format**:\n",
    "  - Sets the format of the tokenized datasets to PyTorch tensors using `set_format(\"torch\")`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 512\n",
    "\n",
    "# Example usage before your model.forward() call\n",
    "\n",
    "\n",
    "def tokenize_and_pad(sentences, tokenizer, vocab, max_length=512):\n",
    "    # Tokenizes sentences, converts tokens to IDs, adds special tokens, and applies padding\n",
    "    tokenized = [tokenizer(re.sub(\"[.,!?\\\\-]\", '', sent.lower())) for sent in sentences]\n",
    "    input_ids = [[vocab['[CLS]']] + [vocab[token] for token in tokens] + [vocab['[SEP]']] for tokens in tokenized]\n",
    "\n",
    "    attn_mask = [[1] * len(tokens) + [0] * (max_length - len(tokens)) for tokens in input_ids]\n",
    "    input_ids = [tokens + [0] * (max_length - len(tokens)) for tokens in input_ids]\n",
    "    return input_ids, attn_mask\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    # Tokenize and pad both premise and hypothesis\n",
    "    premise_input_ids, premise_attn_mask = tokenize_and_pad(examples['premise'], tokenizer, vocab, max_seq_length)\n",
    "    hypothesis_input_ids, hypothesis_attn_mask = tokenize_and_pad(examples['hypothesis'], tokenizer, vocab, max_seq_length)\n",
    "    \n",
    "    # Extract labels\n",
    "    labels = examples[\"label\"]\n",
    "    \n",
    "    return {\n",
    "        \"premise_input_ids\": premise_input_ids,\n",
    "        \"premise_attention_mask\": premise_attn_mask,\n",
    "        \"hypothesis_input_ids\": hypothesis_input_ids,\n",
    "        \"hypothesis_attention_mask\": hypothesis_attn_mask,\n",
    "        \"labels\": labels\n",
    "    }\n",
    "\n",
    "# Map the preprocessing function across the dataset in a batched manner\n",
    "tokenized_datasets = raw_dataset.map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    ")\n",
    "\n",
    "# Remove the original columns to focus on the processed ones and set the format to PyTorch tensors\n",
    "# tokenized_datasets = tokenized_datasets.remove_columns(['premise', 'hypothesis', 'label'])\n",
    "tokenized_datasets.set_format(\"torch\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading with PyTorch DataLoader\n",
    "\n",
    "The provided code snippet demonstrates how to initialize PyTorch `DataLoader` objects for training, evaluation, and testing. Here's a summary:\n",
    "\n",
    "- **Batch Size**:\n",
    "  - `batch_size` is set to `5`, specifying the number of samples per batch.\n",
    "\n",
    "- **Train DataLoader** (`train_dataloader`):\n",
    "  - Initializes a `DataLoader` for the training dataset (`tokenized_datasets['train']`).\n",
    "  - `batch_size` is set to the specified value.\n",
    "  - `shuffle` is set to `True` to shuffle the data during training.\n",
    "\n",
    "- **Evaluation DataLoader** (`eval_dataloader`):\n",
    "  - Initializes a `DataLoader` for the validation dataset (`tokenized_datasets['validation']`).\n",
    "  - `batch_size` is set to the specified value.\n",
    "  - Data is not shuffled during evaluation.\n",
    "\n",
    "- **Test DataLoader** (`test_dataloader`):\n",
    "  - Initializes a `DataLoader` for the test dataset (`tokenized_datasets['test']`).\n",
    "  - `batch_size` is set to the specified value.\n",
    "  - Data is not shuffled during testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# initialize the dataloader\n",
    "batch_size = 5\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets['train'], \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets['validation'], \n",
    "    batch_size=batch_size\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets['test'], \n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 512])\n",
      "torch.Size([5, 512])\n",
      "torch.Size([5, 512])\n",
      "torch.Size([5, 512])\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_dataloader:\n",
    "    print(batch['premise_input_ids'].shape)\n",
    "    print(batch['premise_attention_mask'].shape)\n",
    "    print(batch['hypothesis_input_ids'].shape)\n",
    "    print(batch['hypothesis_attention_mask'].shape)\n",
    "    print(batch['labels'].shape)\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Loading and Summary\n",
    "\n",
    "The provided code snippet loads a pre-trained BERT model along with its hyperparameters. Here's a summary of the process:\n",
    "\n",
    "1. **Loading Pre-trained BERT Model**:\n",
    "   - A custom BERT model is initialized using the `BERT` class from the `model_class.py` module.\n",
    "   - The model's hyperparameters are loaded from the specified file (`./model/bert_best_model.pt`).\n",
    "   - The model is loaded onto the specified device (`device`).\n",
    "\n",
    "2. **Markdown Summary**:\n",
    "   - The markdown summary of the code execution is to be provided. This summary will likely include details about the loaded BERT model and its hyperparameters, as well as any other relevant information about the model loading process.\n",
    "\n",
    "Please note that the specific details of the BERT model and its hyperparameters are not provided in the code snippet and would need to be extracted from the loaded parameters and configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # start from a pretrained bert-base-uncased model\n",
    "from model_class import *\n",
    "\n",
    "# load the model and all its hyperparameters\n",
    "load_path = './model/bert_best_model.pt'\n",
    "params, state = torch.load(load_path)\n",
    "model = BERT(**params, device=device).to(device)\n",
    "model.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37073759\n"
     ]
    }
   ],
   "source": [
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(num_params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling\n",
    "SBERT adds a pooling operation to the output of BERT / RoBERTa to derive a fixed sized sentence embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Pooling Function Definition\n",
    "\n",
    "The provided code defines a function for mean pooling token embeddings. Here's a summary of the function:\n",
    "\n",
    "- **Function Name**: `mean_pool`\n",
    "- **Arguments**:\n",
    "  - `token_embeds`: Tensor containing token embeddings of shape `[batch_size, seq_length, embed_dim]`.\n",
    "  - `attention_mask`: Tensor containing attention mask of shape `[batch_size, seq_length]`, where padding tokens are masked with 0 and non-padding tokens are masked with 1.\n",
    "- **Functionality**:\n",
    "  - Reshapes the attention mask to cover the 768-dimensional embeddings.\n",
    "  - Performs mean-pooling across the token embeddings, excluding the padding tokens specified by the attention mask.\n",
    "  - Returns the mean-pooled representation of the token embeddings.\n",
    "\n",
    "This function can be useful for aggregating token embeddings into a single representation, often used in tasks such as sentence classification or semantic similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define mean pooling function\n",
    "def mean_pool(token_embeds, attention_mask):\n",
    "    # reshape attention_mask to cover 768-dimension embeddings\n",
    "    in_mask = attention_mask.unsqueeze(-1).expand(\n",
    "        token_embeds.size()\n",
    "    ).float()\n",
    "    # perform mean-pooling but exclude padding tokens (specified by in_mask)\n",
    "    pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(\n",
    "        in_mask.sum(1), min=1e-9\n",
    "    )\n",
    "    return pool"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Loss Function\n",
    "\n",
    "## Classification Objective Function \n",
    "We concatenate the sentence embeddings $u$ and $v$ with the element-wise difference  $\\lvert u - v \\rvert $ and multiply the result with the trainable weight  $ W_t ∈  \\mathbb{R}^{3n \\times k}  $:\n",
    "\n",
    "$ o = \\text{softmax}\\left(W^T \\cdot \\left(u, v, \\lvert u - v \\rvert\\right)\\right) $\n",
    "\n",
    "where $n$ is the dimension of the sentence embeddings and k the number of labels. We optimize cross-entropy loss. This structure is depicted in Figure 1.\n",
    "\n",
    "## Regression Objective Function. \n",
    "The cosine similarity between the two sentence embeddings $u$ and $v$ is computed (Figure 2). We use means quared-error loss as the objective function.\n",
    "\n",
    "(Manhatten / Euclidean distance, semantically  similar sentences can be found.)\n",
    "\n",
    "<img src=\"./figures/sbert-architecture.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function Definitions: Configurations and Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configurations(u,v):\n",
    "    # build the |u-v| tensor\n",
    "    uv = torch.sub(u, v)   # batch_size,hidden_dim\n",
    "    uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "    \n",
    "    # concatenate u, v, |u-v|\n",
    "    x = torch.cat([u, v, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "    return x\n",
    "\n",
    "def cosine_similarity(u, v):\n",
    "    dot_product = np.dot(u, v)\n",
    "    norm_u = np.linalg.norm(u)\n",
    "    norm_v = np.linalg.norm(v)\n",
    "    similarity = dot_product / (norm_u * norm_v)\n",
    "    return similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./figures/sbert-ablation.png\" width=\"350\" height=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Initialization and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_head = torch.nn.Linear(768*3, 3).to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
    "optimizer_classifier = torch.optim.Adam(classifier_head.parameters(), lr=2e-5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Rate Schedulers with Warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shafisourov/anaconda3/envs/nlu/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# and setup a warmup for the first ~10% steps\n",
    "total_steps = int(len(raw_dataset) / batch_size)\n",
    "warmup_steps = int(0.1 * total_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler.step()\n",
    "\n",
    "scheduler_classifier = get_linear_schedule_with_warmup(\n",
    "\t\toptimizer_classifier, num_warmup_steps=warmup_steps,\n",
    "  \tnum_training_steps=total_steps - warmup_steps\n",
    ")\n",
    "\n",
    "# then during the training loop we update the scheduler per step\n",
    "scheduler_classifier.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Function Overview\n",
    "\n",
    "The `train` function is designed to train a BERT-based model with a classifier head. It follows a structured approach to process the data, compute predictions, calculate losses, and update model parameters. Below is an overview of the key steps performed by the `train` function:\n",
    "\n",
    "### Data Preparation\n",
    "1. Tokenization: The input sequences are tokenized using the BERT tokenizer.\n",
    "2. Device Transfer: Tensors are moved to the active device for computation.\n",
    "\n",
    "### Model Forward Pass\n",
    "1. Token Embeddings Extraction: Token embeddings are extracted from the BERT model for both input sequences.\n",
    "2. Mean Pooling: Mean-pooled representations are computed for each sequence.\n",
    "3. Concatenation: The mean-pooled representations are concatenated with their absolute difference.\n",
    "\n",
    "### Classifier Head Operation\n",
    "1. Forward Pass: The concatenated representations are passed through the classifier head to obtain predictions.\n",
    "2. Loss Calculation: The cross-entropy loss is computed between the predicted and true labels.\n",
    "\n",
    "### Backpropagation and Optimization\n",
    "1. Gradients Calculation: Gradients with respect to the loss are computed.\n",
    "2. Parameter Update: Model parameters are updated using the optimizer.\n",
    "3. Learning Rate Adjustment: Learning rate is updated using the scheduler.\n",
    "\n",
    "Overall, the `train` function efficiently handles the training process, ensuring proper data processing, model computation, and parameter optimization.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def train(model, classifier_head, data, optimizer, optimizer_classifier, scheduler, scheduler_classifier, criterion, device):\n",
    "    epoch_loss = []\n",
    "    model.train()\n",
    "    classifier_head.train()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(data, leave=True, desc='Training: ')):\n",
    "        # zero all gradients on each new step\n",
    "        optimizer.zero_grad()\n",
    "        optimizer_classifier.zero_grad()\n",
    "        \n",
    "        # prepare batches and more all to the active device\n",
    "        inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "        inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "        attention_a = batch['premise_attention_mask'].to(device)\n",
    "        attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "        segment_ids = torch.zeros(batch_size, max_seq_length, dtype=torch.int32).to(device)  # each input contains only one sentence hence we define them all as sentence '0'\n",
    "        label = batch['labels'].to(device)\n",
    "        \n",
    "        # extract token embeddings from BERT at last_hidden_state\n",
    "        u_last_hidden_state = model.get_last_hidden_state(inputs_ids_a, segment_ids)  \n",
    "        v_last_hidden_state = model.get_last_hidden_state(inputs_ids_b, segment_ids)  \n",
    "\n",
    "        # u_last_hidden_state = u.last_hidden_state # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "        # v_last_hidden_state = v.last_hidden_state # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "         # get the mean pooled vectors\n",
    "        u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
    "        v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
    "        \n",
    "        # build the |u-v| tensor\n",
    "        uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
    "        uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "        \n",
    "        # concatenate u, v, |u-v|\n",
    "        x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "        \n",
    "        # process concatenated tensor through classifier_head\n",
    "        x = classifier_head(x) #batch_size, classifer\n",
    "        \n",
    "        # calculate the 'softmax-loss' between predicted and true label\n",
    "        loss = criterion(x, label)\n",
    "        \n",
    "        # using loss, calculate gradients and then optimizerize\n",
    "        loss.backward()\n",
    "        epoch_loss.append(loss.item())\n",
    "        optimizer.step()\n",
    "        optimizer_classifier.step()\n",
    "\n",
    "        scheduler.step() # update learning rate scheduler\n",
    "        scheduler_classifier.step()\n",
    "\n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Function Overview\n",
    "\n",
    "The `evaluate` function is responsible for evaluating the performance of a trained BERT-based model with a classifier head on a validation or test dataset. Similar to the training function, it follows a structured approach to process the data, compute predictions, calculate losses, and aggregate evaluation metrics. Below is an overview of the key steps performed by the `evaluate` function:\n",
    "\n",
    "### Data Preparation\n",
    "1. Tokenization: The input sequences are tokenized using the BERT tokenizer.\n",
    "2. Device Transfer: Tensors are moved to the active device for computation.\n",
    "\n",
    "### Model Forward Pass\n",
    "1. Token Embeddings Extraction: Token embeddings are extracted from the BERT model for both input sequences.\n",
    "2. Mean Pooling: Mean-pooled representations are computed for each sequence.\n",
    "3. Concatenation: The mean-pooled representations are concatenated with their absolute difference.\n",
    "\n",
    "### Classifier Head Operation\n",
    "1. Forward Pass: The concatenated representations are passed through the classifier head to obtain predictions.\n",
    "2. Loss Calculation: The cross-entropy loss is computed between the predicted and true labels.\n",
    "\n",
    "### Evaluation Metrics Calculation\n",
    "1. Loss Aggregation: Losses across all batches are aggregated to compute the average loss.\n",
    "\n",
    "### Model Evaluation\n",
    "1. Evaluation Output: The average loss is returned as the evaluation metric.\n",
    "\n",
    "Overall, the `evaluate` function provides a systematic approach to assess the model's performance on unseen data, facilitating model evaluation and comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, classifier_head, data, criterion, device):\n",
    "    epoch_loss = []\n",
    "    model.eval()\n",
    "    classifier_head.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for step, batch in enumerate(tqdm(data, leave=True, desc='Evaluate: ')):\n",
    "            \n",
    "            # prepare batches and more all to the active device\n",
    "            inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "            inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "            attention_a = batch['premise_attention_mask'].to(device)\n",
    "            attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "            segment_ids = torch.zeros(batch_size, max_seq_length, dtype=torch.int32).to(device)  # each input contains only one sentence hence we define them all as sentence '0'\n",
    "            label = batch['labels'].to(device)\n",
    "            \n",
    "            # extract token embeddings from BERT at last_hidden_state\n",
    "            u_last_hidden_state = model.get_last_hidden_state(inputs_ids_a, segment_ids)  \n",
    "            v_last_hidden_state = model.get_last_hidden_state(inputs_ids_b, segment_ids)  \n",
    "\n",
    "            # u_last_hidden_state = u.last_hidden_state # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "            # v_last_hidden_state = v.last_hidden_state # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "            # get the mean pooled vectors\n",
    "            u_mean_pool = mean_pool(u_last_hidden_state, attention_a) # batch_size, hidden_dim\n",
    "            v_mean_pool = mean_pool(v_last_hidden_state, attention_b) # batch_size, hidden_dim\n",
    "            \n",
    "            # build the |u-v| tensor\n",
    "            uv = torch.sub(u_mean_pool, v_mean_pool)   # batch_size,hidden_dim\n",
    "            uv_abs = torch.abs(uv) # batch_size,hidden_dim\n",
    "            \n",
    "            # concatenate u, v, |u-v|\n",
    "            x = torch.cat([u_mean_pool, v_mean_pool, uv_abs], dim=-1) # batch_size, 3*hidden_dim\n",
    "            \n",
    "            # process concatenated tensor through classifier_head\n",
    "            x = classifier_head(x) #batch_size, classifer\n",
    "            \n",
    "            # calculate the 'softmax-loss' between predicted and true label\n",
    "            loss = criterion(x, label)\n",
    "            epoch_loss.append(loss.item())\n",
    "\n",
    "    return np.mean(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_path = './model/best_s_bert_classifier_head.pt'\n",
    "model_path = './model/best_s_bert.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Process\n",
    "\n",
    "This markdown cell outlines the training and evaluation process for the BERT model with the added classifier head.\n",
    "\n",
    "### Training Loop\n",
    "- The training loop iterates over the specified number of epochs.\n",
    "- For each epoch:\n",
    "  - The model is trained on the training dataset using the `train` function, which computes the loss, calculates gradients, and updates the model parameters.\n",
    "  - The model is then evaluated on the validation dataset using the `evaluate` function to monitor its performance.\n",
    "  - Training and validation losses are recorded for visualization.\n",
    "  - If the validation loss improves compared to the best validation loss so far, both the classifier head and the model's parameters are saved.\n",
    "\n",
    "### Evaluation\n",
    "- The `evaluate` function evaluates the model's performance on the validation dataset by computing the loss without updating the model parameters.\n",
    "- The loss is calculated using the specified criterion (in this case, CrossEntropyLoss).\n",
    "- This process allows us to monitor the model's performance on unseen data and prevent overfitting.\n",
    "\n",
    "### Results\n",
    "- After training, the model's performance can be assessed using the test dataset.\n",
    "- The best model (with the lowest validation loss) can be loaded and evaluated on the test set to obtain the final performance metrics.\n",
    "\n",
    "By following this process, we ensure that the model learns from the training data while generalizing well to unseen data, leading to better overall performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [05:42<00:00, 20.14s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:15<00:00,  5.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 5m 57s\n",
      "\tTrain Loss: 1.169\n",
      "\t Val. Loss: 1.032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [05:19<00:00, 18.81s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:15<00:00,  5.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 5m 35s\n",
      "\tTrain Loss: 1.164\n",
      "\t Val. Loss: 1.036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [05:04<00:00, 17.93s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:21<00:00,  7.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 5m 26s\n",
      "\tTrain Loss: 1.161\n",
      "\t Val. Loss: 1.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [05:23<00:00, 19.02s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:14<00:00,  4.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 5m 37s\n",
      "\tTrain Loss: 1.161\n",
      "\t Val. Loss: 1.039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [05:23<00:00, 19.01s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:16<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 5m 39s\n",
      "\tTrain Loss: 1.167\n",
      "\t Val. Loss: 1.042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [05:58<00:00, 21.08s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:13<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 6m 12s\n",
      "\tTrain Loss: 1.168\n",
      "\t Val. Loss: 1.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [04:28<00:00, 15.77s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:14<00:00,  4.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 4m 42s\n",
      "\tTrain Loss: 1.171\n",
      "\t Val. Loss: 1.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [04:30<00:00, 15.90s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:14<00:00,  4.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 4m 44s\n",
      "\tTrain Loss: 1.174\n",
      "\t Val. Loss: 1.038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [04:17<00:00, 15.17s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:14<00:00,  4.72s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 4m 32s\n",
      "\tTrain Loss: 1.159\n",
      "\t Val. Loss: 1.049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 17/17 [04:18<00:00, 15.23s/it]\n",
      "Evaluate: 100%|██████████| 3/3 [00:13<00:00,  4.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 4m 32s\n",
      "\tTrain Loss: 1.161\n",
      "\t Val. Loss: 1.051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 10\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "# 1 epoch should be enough, increase if wanted\n",
    "for epoch in range(num_epoch):\n",
    "    start_time = time.time()\n",
    "    train_loss = train(model, classifier_head, train_dataloader, optimizer, optimizer_classifier, scheduler, scheduler_classifier, criterion, device)\n",
    "    val_loss = evaluate(model, classifier_head, eval_dataloader, criterion, device)\n",
    "\n",
    "    #for plotting\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "    end_time = time.time()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    # save the model only when its validation loss is lower than all its predecessors\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(classifier_head, head_path)  # save the classifier head\n",
    "        torch.save([model.params, model.state_dict()], model_path)  # save the model's parameters and state to a file\n",
    "        \n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {val_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Training Loss for Sentence BERT Model: 1.1655\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average training loss\n",
    "average_train_loss_sentence_bert = sum(train_losses) / len(train_losses)\n",
    "\n",
    "# Display the average training loss\n",
    "print(\"Average Training Loss for Sentence BERT Model:\", average_train_loss_sentence_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Loss for Sentence BERT Model: 1.0398\n"
     ]
    }
   ],
   "source": [
    "# Calculate the average validation loss\n",
    "average_val_loss_sentence_bert = sum(val_losses) / len(val_losses)\n",
    "\n",
    "# Display the average validation loss\n",
    "print(\"Average Validation Loss for Sentence BERT Model:\", average_val_loss_sentence_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluate: 100%|██████████| 3/3 [00:17<00:00,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 1.1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_average_test_loss(model, classifier_head, test_dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Calculate the average test loss for the Sentence-BERT model.\n",
    "\n",
    "    Args:\n",
    "    - model (torch.nn.Module): The Sentence-BERT model.\n",
    "    - classifier_head (torch.nn.Module): The classifier head added on top of the Sentence-BERT model.\n",
    "    - test_dataloader (torch.utils.data.DataLoader): DataLoader for test data.\n",
    "    - criterion (torch.nn.Module): Loss function.\n",
    "    - device (str): Device to run the evaluation on ('cuda' or 'cpu').\n",
    "\n",
    "    Returns:\n",
    "    - float: The average test loss.\n",
    "    \"\"\"\n",
    "    # Evaluate the model on the test dataset\n",
    "    average_test_loss = evaluate(model, classifier_head, test_dataloader, criterion, device)\n",
    "    \n",
    "    return average_test_loss\n",
    "\n",
    "# Use the function to calculate the average test loss\n",
    "average_test_loss = calculate_average_test_loss(model, classifier_head, test_dataloader, criterion, device)\n",
    "\n",
    "print(f\"Average Test Loss: {average_test_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.1111, Recall: 0.3333, F1 Score: 0.1667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shafisourov/anaconda3/envs/nlu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import torch\n",
    "\n",
    "def evaluate_and_predict(model, classifier_head, data_loader, device):\n",
    "    model.eval()\n",
    "    classifier_head.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "            inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "            attention_a = batch['premise_attention_mask'].to(device)\n",
    "            attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "            segment_ids = torch.zeros(batch['labels'].size(0), max_seq_length, dtype=torch.int32).to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            u_last_hidden_state = model.get_last_hidden_state(inputs_ids_a, segment_ids)  \n",
    "            v_last_hidden_state = model.get_last_hidden_state(inputs_ids_b, segment_ids)\n",
    "\n",
    "            u_mean_pool = mean_pool(u_last_hidden_state, attention_a)\n",
    "            v_mean_pool = mean_pool(v_last_hidden_state, attention_b)\n",
    "\n",
    "            concatenated_features = torch.cat([u_mean_pool, v_mean_pool, torch.abs(u_mean_pool - v_mean_pool)], dim=-1)\n",
    "            logits = classifier_head(concatenated_features)\n",
    "            predictions.extend(torch.argmax(logits, dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate Precision, Recall, and F1 Score\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
    "\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Calculate metrics\n",
    "precision, recall, f1 = evaluate_and_predict(model, classifier_head, test_dataloader, device)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Progress Visualization\n",
    "\n",
    "The plot above shows the training and validation losses across updates during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'loss')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(5, 3))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(train_losses, label = 'train loss')\n",
    "ax.plot(val_losses, label = 'validation loss')\n",
    "plt.legend()\n",
    "ax.set_xlabel('updates')\n",
    "ax.set_ylabel('loss')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Function for Single Sentence Input\n",
    "\n",
    "This function `process_text` is used to preprocess a single sentence for input to a BERT-based model.\n",
    "\n",
    "### Input\n",
    "- `sentence`: The input sentence to be processed.\n",
    "- `tokenizer`: The tokenizer used to tokenize the sentence.\n",
    "- `vocab`: The vocabulary containing token-to-index mappings.\n",
    "- `max_seq_length`: The maximum sequence length expected by the model.\n",
    "\n",
    "### Output\n",
    "- A dictionary containing the preprocessed input:\n",
    "  - `input_ids`: Tensor containing token IDs of the input sentence.\n",
    "  - `attention_mask`: Tensor containing attention mask indicating which tokens are real and which are padding.\n",
    "\n",
    "### Functionality\n",
    "- Tokenizes the input sentence using the provided tokenizer.\n",
    "- Converts tokens to token IDs using the provided vocabulary.\n",
    "- Adds special tokens `[CLS]` and `[SEP]` to mark the beginning and end of the sentence.\n",
    "- Adds padding tokens `[PAD]` to ensure the sequence length matches `max_seq_length`.\n",
    "- Constructs an attention mask to distinguish real tokens from padding tokens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(sentence, tokenizer, vocab, max_seq_length):\n",
    "    tokens = tokenizer(re.sub(\"[.,!?\\\\-]\", '', sentence.lower()))\n",
    "    input_ids = [vocab['[CLS]']] + [vocab[token] for token in tokens] + [vocab['[SEP]']]\n",
    "    n_pad = max_seq_length - len(input_ids)\n",
    "    attention_mask = ([1] * len(input_ids)) + ([0] * n_pad)\n",
    "    input_ids = input_ids + ([0] * n_pad)\n",
    "\n",
    "    return {'input_ids': torch.LongTensor(input_ids).reshape(1, -1),\n",
    "            'attention_mask': torch.LongTensor(attention_mask).reshape(1, -1)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Similarity Calculation Function\n",
    "\n",
    "This function `calculate_similarity` is used to calculate the cosine similarity between two input sentences using a pretrained BERT-based model.\n",
    "\n",
    "### Inputs\n",
    "- `model`: The pretrained BERT-based model used for encoding sentences.\n",
    "- `tokenizer`: The tokenizer used to tokenize the sentences.\n",
    "- `vocab`: The vocabulary containing token-to-index mappings.\n",
    "- `sentence_a`: The first input sentence.\n",
    "- `sentence_b`: The second input sentence.\n",
    "- `device`: The device (CPU or GPU) where the model will be executed.\n",
    "\n",
    "### Output\n",
    "- The cosine similarity score between the two input sentences.\n",
    "\n",
    "### Functionality\n",
    "- Tokenizes and converts the input sentences into input IDs and attention masks compatible with the BERT model.\n",
    "- Extracts token embeddings for both sentences from the BERT model.\n",
    "- Calculates the mean-pooled vectors for both sentences.\n",
    "- Computes the cosine similarity between the mean-pooled vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(model, tokenizer, vocab, sentence_a, sentence_b, device):\n",
    "    # Tokenize and convert sentences to input IDs and attention masks\n",
    "    inputs_a = process_text(sentence_a, tokenizer, vocab, max_seq_length)\n",
    "    inputs_b = process_text(sentence_b, tokenizer, vocab, max_seq_length)\n",
    "    \n",
    "\n",
    "    # Move input IDs and attention masks to the active device\n",
    "    inputs_ids_a = inputs_a['input_ids'].to(device)\n",
    "    attention_a = inputs_a['attention_mask'].to(device)\n",
    "    inputs_ids_b = inputs_b['input_ids'].to(device)\n",
    "    attention_b = inputs_b['attention_mask'].to(device)\n",
    "    segment_ids = torch.zeros(1, max_seq_length, dtype=torch.int32).to(device)\n",
    "\n",
    "    # Extract token embeddings from BERT\n",
    "    u = model.get_last_hidden_state(inputs_ids_a, segment_ids)  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "    v = model.get_last_hidden_state(inputs_ids_b, segment_ids)  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "    # u = model(inputs_ids_a, attention_mask=attention_a)[0]  # all token embeddings A = batch_size, seq_len, hidden_dim\n",
    "    # v = model(inputs_ids_b, attention_mask=attention_b)[0]  # all token embeddings B = batch_size, seq_len, hidden_dim\n",
    "\n",
    "    # Get the mean-pooled vectors\n",
    "    u = mean_pool(u, attention_a).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "    v = mean_pool(v, attention_b).detach().cpu().numpy().reshape(-1)  # batch_size, hidden_dim\n",
    "\n",
    "    # Calculate cosine similarity\n",
    "    similarity_score = cosine_similarity(u.reshape(1, -1), v.reshape(1, -1))[0, 0]\n",
    "\n",
    "    return similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9240\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sentence_a = 'Your contribution helped make it possible for us to provide our students with a quality education.'\n",
    "sentence_b = \"Your contributions were of no help with our students' education.\"\n",
    "similarity = calculate_similarity(model, tokenizer, vocab, sentence_a, sentence_b, device)\n",
    "print(f\"Cosine Similarity: {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Similarity:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                     \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.929920494556427"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "max_len = max_seq_length\n",
    "def cosine_similarity(u, v):\n",
    "    \"\"\"\n",
    "    Compute the cosine similarity between two tensors.\n",
    "    \"\"\"\n",
    "    dot_product = (u * v).sum()\n",
    "    norm_u = u.norm(2)\n",
    "    norm_v = v.norm(2)\n",
    "    similarity = dot_product / (norm_u * norm_v)\n",
    "    return similarity.item()\n",
    "\n",
    "def calculate_average_cosine_similarity(model, data_loader, device):\n",
    "    \"\"\"\n",
    "    Calculate the average cosine similarity between the sentence embeddings\n",
    "    of pairs in the dataset.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    similarities = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, desc='Calculating Similarity', leave=False):\n",
    "            inputs_ids_a = batch['premise_input_ids'].to(device)\n",
    "            inputs_ids_b = batch['hypothesis_input_ids'].to(device)\n",
    "            attention_a = batch['premise_attention_mask'].to(device)\n",
    "            attention_b = batch['hypothesis_attention_mask'].to(device)\n",
    "            segment_ids = torch.zeros(inputs_ids_a.size(0), max_len, dtype=torch.int32).to(device)\n",
    "\n",
    "            u_last_hidden_state = model.get_last_hidden_state(inputs_ids_a, segment_ids)\n",
    "            v_last_hidden_state = model.get_last_hidden_state(inputs_ids_b, segment_ids)\n",
    "\n",
    "            u_mean_pool = mean_pool(u_last_hidden_state, attention_a)\n",
    "            v_mean_pool = mean_pool(v_last_hidden_state, attention_b)\n",
    "\n",
    "            similarity = cosine_similarity(u_mean_pool, v_mean_pool)\n",
    "            similarities.append(similarity)\n",
    "\n",
    "    average_similarity = np.mean(similarities)\n",
    "    return average_similarity\n",
    "\n",
    "# Assuming test_dataloader is already defined and contains the test dataset\n",
    "# device is defined as per the previous context\n",
    "average_similarity = calculate_average_cosine_similarity(model, test_dataloader, device)\n",
    "average_similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
