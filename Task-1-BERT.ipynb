{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bSz5jzj61nHc"
      },
      "source": [
        "# BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imported Libraries\n",
        "\n",
        "The code imports essential Python libraries for mathematical operations (`math`), regular expressions (`re`), random number generation (`random`), numerical computing (`numpy`), and deep learning with PyTorch (`torch`). Specifically, PyTorch modules for neural networks (`torch.nn`) and optimization (`torch.optim`) are imported. These imports lay the groundwork for various computational tasks, including data manipulation, model building, and optimization.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import re\n",
        "from random import *\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The dataset \"nuvocare/WikiMedical_sentence_similarity\" from Hugging Face provides pairs of sentences with similarity labels, suitable for tasks like semantic similarity assessment in the medical domain.\n",
        "\n",
        "\n",
        "\n",
        "The dataset consists of a train set with 50,712 pairs and a test set with 21,735 pairs. After splitting, the new train set contains 43,355 pairs, and the new test set contains 7,357 pairs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shafisourov/anaconda3/envs/nlu/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"nuvocare/WikiMedical_sentence_similarity\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text1', 'text2', 'label'],\n",
              "        num_rows: 50712\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text1', 'text2', 'label'],\n",
              "        num_rows: 21735\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New Train dataset size: 85\n",
            "New Validation dataset size: 15\n",
            "New Test dataset size: 15\n"
          ]
        }
      ],
      "source": [
        "# # Define the split sizes\n",
        "# train_size = 85\n",
        "# val_size = 15 \n",
        "# test_size = 15  # Explicit for clarity, though it's simply 100 - 85\n",
        "\n",
        "# # Apply the split to both 'train' and 'test' sets in the DatasetDict\n",
        "# new_train = dataset['train'].select(range(train_size))\n",
        "# new_test = dataset['train'].select(range(train_size, train_size + val_size))\n",
        "# new_test = dataset['train'].select(range(train_size + val_size, train_size + val_size + test_size))\n",
        "\n",
        "# # Additionally, if you wish to apply the split to the original 'test' dataset as well, you can do:\n",
        "# # For clarity, showing how to reassign within the DatasetDict, but typically, you adjust only the 'train' part for such operations\n",
        "# dataset['train'] = new_train\n",
        "# dataset['test'] = dataset['test'].select(range(test_size))\n",
        "\n",
        "# # Confirming the new sizes\n",
        "# print(f\"New Train dataset size: {len(dataset['train'])}\")\n",
        "# print(f\"New Test dataset size: {len(dataset['test'])}\")\n",
        "\n",
        "# Define the split sizes\n",
        "train_size = 85\n",
        "val_size = 15 \n",
        "test_size = 15  # Explicit for clarity, though it's simply 100 - 85\n",
        "\n",
        "# Apply the split to both 'train' and 'test' sets in the DatasetDict\n",
        "new_train = dataset['train'].select(range(train_size))\n",
        "new_val = dataset['train'].select(range(train_size, train_size + val_size))\n",
        "new_test = dataset['train'].select(range(train_size + val_size, train_size + val_size + test_size))\n",
        "\n",
        "# Additionally, if you wish to apply the split to the original 'test' dataset as well, you can do:\n",
        "# For clarity, showing how to reassign within the DatasetDict, but typically, you adjust only the 'train' part for such operations\n",
        "dataset['train'] = new_train\n",
        "dataset['validation'] = new_val\n",
        "dataset['test'] = new_test\n",
        "\n",
        "# Confirming the new sizes\n",
        "print(f\"New Train dataset size: {len(dataset['train'])}\")\n",
        "print(f\"New Validation dataset size: {len(dataset['validation'])}\")\n",
        "print(f\"New Test dataset size: {len(dataset['test'])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text1', 'text2', 'label'],\n",
              "        num_rows: 85\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text1', 'text2', 'label'],\n",
              "        num_rows: 15\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text1', 'text2', 'label'],\n",
              "        num_rows: 15\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Preprocessing\n",
        "\n",
        "### Tokenization and numericalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Transformation of Dataset\n",
        "\n",
        "The provided code demonstrates the transformation of a dataset using a custom function named `transform_data`. Here's a breakdown of the process:\n",
        "\n",
        "1. **Imports**: The code imports necessary libraries such as `datasets`, `numpy`, `random`, and `re`.\n",
        "\n",
        "2. **Transformation Function**: The `transform_data` function defines a transformation process for each example in the dataset. It preprocesses text data by converting it to lowercase and removing punctuation. Then, it randomly selects pairs of sentences and assigns a binary label (`isNext`) based on whether they are similar or not.\n",
        "\n",
        "3. **Application of Transformation**: The transformation is applied directly to each split in the dataset (`train` and `test`) using the `map` function. The transformation function is applied to each example, and the original columns (`text1`, `text2`, `label`) are removed.\n",
        "\n",
        "4. **Result**: The transformed dataset (`transformed_dataset`) is obtained, containing the preprocessed examples with the new structure. The sizes of the transformed train and test datasets are printed for verification.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformed Train dataset size: 85\n",
            "Transformed Validation dataset size: 15\n",
            "Transformed Test dataset size: 15\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import numpy as np\n",
        "import random\n",
        "import re\n",
        "\n",
        "# Define your transformation function\n",
        "def transform_data(example):\n",
        "    text1 = re.sub(\"[.,!?\\\\-]\", '', example['text1'].lower())\n",
        "    text2 = re.sub(\"[.,!?\\\\-]\", '', example['text2'].lower())\n",
        "    label = example['label']\n",
        "\n",
        "    if np.random.random() < 0.5:\n",
        "        return {'text1': text1, 'text2': text2, 'isNext': label == 1}  # Assuming 1 indicates similarity\n",
        "    else:\n",
        "        return {'text1': text2, 'text2': text1, 'isNext': label == 1}  # Flip text1 and text2\n",
        "\n",
        "# Assuming 'dataset' is your DatasetDict\n",
        "# Apply the transformation directly to each split in the DatasetDict\n",
        "transformed_dataset = {\n",
        "    split: dataset[split].map(transform_data, remove_columns=['text1', 'text2', 'label'])\n",
        "    for split in dataset.keys()\n",
        "}\n",
        "\n",
        "# Now, 'transformed_dataset' should be correctly transformed\n",
        "print(f\"Transformed Train dataset size: {len(transformed_dataset['train'])}\")\n",
        "print(f\"Transformed Validation dataset size: {len(transformed_dataset['validation'])}\")\n",
        "print(f\"Transformed Test dataset size: {len(transformed_dataset['test'])}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'train': Dataset({\n",
              "     features: ['text1', 'text2', 'isNext'],\n",
              "     num_rows: 85\n",
              " }),\n",
              " 'test': Dataset({\n",
              "     features: ['text1', 'text2', 'isNext'],\n",
              "     num_rows: 15\n",
              " }),\n",
              " 'validation': Dataset({\n",
              "     features: ['text1', 'text2', 'isNext'],\n",
              "     num_rows: 15\n",
              " })}"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformed_dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenization and Vocabulary Building\n",
        "\n",
        "The provided code demonstrates tokenization of text data using the `torchtext` library and building a vocabulary from the tokenized text. Here's a summary of the process:\n",
        "\n",
        "1. **Imports**: Necessary libraries such as `torch`, `datasets`, `torchtext`, and related modules are imported.\n",
        "\n",
        "2. **Tokenization**: The `tokenize_data` function is defined to tokenize text data in batches. It tokenizes each text in the batch for both 'text1' and 'text2' fields.\n",
        "\n",
        "3. **Tokenization Application**: Tokenization is applied to each split in the transformed dataset using the `map` function. The tokenized texts are stored in a new column and the original text columns ('text1' and 'text2') are removed.\n",
        "\n",
        "4. **Vocabulary Building**:\n",
        "    - The special tokens for padding, classification, separator, masking, and unknown tokens are defined.\n",
        "    - A custom function `flat_map` is defined to flatten the token lists.\n",
        "    - The `build_vocab_from_iterator` function is called to build a vocabulary from the flattened token lists of the training data, considering the defined special tokens.\n",
        "    - The default index of the vocabulary is set to the unknown token ('[UNK]').\n",
        "    \n",
        "5. **Vocabulary Saving**: The built vocabulary is saved for later use.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Map: 100%|██████████| 15/15 [00:00<00:00, 914.46 examples/s]\n",
            "Map: 100%|██████████| 15/15 [00:00<00:00, 410.25 examples/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from datasets import load_dataset\n",
        "import torchtext\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# Load the 'basic_english' tokenizer\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "# Adjust the tokenize_data function to handle batch processing\n",
        "def tokenize_data(batch, tokenizer):\n",
        "    # Tokenize each text in the batch for text1 and text2\n",
        "    text1_tokens = [tokenizer(text) for text in batch['text1']]\n",
        "    text2_tokens = [tokenizer(text) for text in batch['text2']]\n",
        "    # Return a dictionary with the tokenized texts\n",
        "    return {'text1_tokens': text1_tokens, 'text2_tokens': text2_tokens}\n",
        "\n",
        "# Apply tokenization to each split in your transformed dataset\n",
        "tokenized_dataset = {\n",
        "    split: transformed_dataset[split].map(lambda batch: tokenize_data(batch, tokenizer), batched=True, remove_columns=['text1', 'text2'])\n",
        "    for split in transformed_dataset.keys()\n",
        "}\n",
        "\n",
        "# Proceed with building the vocab\n",
        "special_tokens = ['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]']\n",
        "\n",
        "# Since build_vocab_from_iterator expects a flat iterator of tokens, you need to flatten the token lists\n",
        "def flat_map(tokens_lists):\n",
        "    for tokens in tokens_lists:\n",
        "        for token in tokens:\n",
        "            yield token\n",
        "\n",
        "# Adjust the call to build_vocab_from_iterator\n",
        "vocab = build_vocab_from_iterator(\n",
        "    flat_map(tokenized_dataset['train']['text1_tokens'] + tokenized_dataset['train']['text2_tokens']),\n",
        "    specials=special_tokens\n",
        ")\n",
        "vocab.set_default_index(vocab['[UNK]'])\n",
        "\n",
        "# Save vocab for later use\n",
        "torch.save(vocab, './model/vocab.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total number of tokens in vocab: 93\n"
          ]
        }
      ],
      "source": [
        "print(f\"Total number of tokens in vocab: {len(vocab)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index of '[PAD]': 0\n",
            "Index of '[CLS]': 1\n",
            "Index of '[SEP]': 2\n",
            "Index of '[MASK]': 3\n",
            "Index of '[UNK]': 4\n",
            "Index of 'the': 4\n",
            "Index of 'of': 4\n",
            "Index of 'and': 4\n"
          ]
        }
      ],
      "source": [
        "tokens_to_check = ['[PAD]', '[CLS]', '[SEP]', '[MASK]', '[UNK]', 'the', 'of', 'and']\n",
        "for token in tokens_to_check:\n",
        "    print(f\"Index of '{token}': {vocab[token]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'isNext': False,\n",
              " 'text1_tokens': ['econometric',\n",
              "  'studies',\n",
              "  'have',\n",
              "  'shown',\n",
              "  'that',\n",
              "  'this',\n",
              "  'effect',\n",
              "  'cannot',\n",
              "  'be',\n",
              "  'explained',\n",
              "  'by',\n",
              "  'a',\n",
              "  'variety',\n",
              "  'of',\n",
              "  'alternative',\n",
              "  'factors',\n",
              "  'including',\n",
              "  'differential',\n",
              "  'trends',\n",
              "  'across',\n",
              "  'areas',\n",
              "  'changing',\n",
              "  'crop',\n",
              "  'prices',\n",
              "  'shifts',\n",
              "  'in',\n",
              "  'certain',\n",
              "  'educational',\n",
              "  'and',\n",
              "  'health',\n",
              "  'policies',\n",
              "  'and',\n",
              "  'the',\n",
              "  'effect',\n",
              "  'of',\n",
              "  'malaria',\n",
              "  'eradication',\n",
              "  'no',\n",
              "  'significant',\n",
              "  'contemporaneous',\n",
              "  'results',\n",
              "  'were',\n",
              "  'found',\n",
              "  'for',\n",
              "  'adults',\n",
              "  'who',\n",
              "  'should',\n",
              "  'have',\n",
              "  'benefited',\n",
              "  'less',\n",
              "  'from',\n",
              "  'the',\n",
              "  'intervention',\n",
              "  'owing',\n",
              "  'to',\n",
              "  'their',\n",
              "  'substantially',\n",
              "  'lower',\n",
              "  '(',\n",
              "  'prior',\n",
              "  ')',\n",
              "  'infection',\n",
              "  'rates',\n",
              "  'the',\n",
              "  'program',\n",
              "  'nearly',\n",
              "  'eradicated',\n",
              "  'hookworm',\n",
              "  'and',\n",
              "  'would',\n",
              "  'flourish',\n",
              "  'afterward',\n",
              "  'with',\n",
              "  'new',\n",
              "  'funding',\n",
              "  'as',\n",
              "  'the',\n",
              "  'rockefeller',\n",
              "  'foundation',\n",
              "  'international',\n",
              "  'health',\n",
              "  'divisionthe',\n",
              "  'rfs',\n",
              "  'hookworm',\n",
              "  'campaign',\n",
              "  'in',\n",
              "  'mexico',\n",
              "  'showed',\n",
              "  'how',\n",
              "  'science',\n",
              "  'and',\n",
              "  'politics',\n",
              "  'play',\n",
              "  'a',\n",
              "  'role',\n",
              "  'in',\n",
              "  'developing',\n",
              "  'health',\n",
              "  'policies',\n",
              "  'it',\n",
              "  'brought',\n",
              "  'together',\n",
              "  'government',\n",
              "  'officials',\n",
              "  'health',\n",
              "  'officials',\n",
              "  'public',\n",
              "  'health',\n",
              "  'workers',\n",
              "  'rockefeller',\n",
              "  'officials',\n",
              "  'and',\n",
              "  'the',\n",
              "  'community',\n",
              "  'this',\n",
              "  'campaign',\n",
              "  'was',\n",
              "  'launched',\n",
              "  'to',\n",
              "  'eradicate',\n",
              "  'hookworms',\n",
              "  'in',\n",
              "  'mexico',\n",
              "  'although',\n",
              "  'the',\n",
              "  'campaign',\n",
              "  'did',\n",
              "  'not',\n",
              "  'focus',\n",
              "  'on',\n",
              "  'longterm',\n",
              "  'treatments',\n",
              "  'it',\n",
              "  'did',\n",
              "  'set',\n",
              "  'the',\n",
              "  'terms',\n",
              "  'of',\n",
              "  'the',\n",
              "  'relationship',\n",
              "  'between',\n",
              "  'mexico',\n",
              "  'and',\n",
              "  'the',\n",
              "  'rockefeller',\n",
              "  'foundation',\n",
              "  'the',\n",
              "  'scientific',\n",
              "  'knowledge',\n",
              "  'behind',\n",
              "  'this',\n",
              "  'campaign',\n",
              "  'helped',\n",
              "  'shape',\n",
              "  'public',\n",
              "  'health',\n",
              "  'policies',\n",
              "  'improved',\n",
              "  'public',\n",
              "  'health',\n",
              "  'and',\n",
              "  'built',\n",
              "  'a',\n",
              "  'strong',\n",
              "  'relationship',\n",
              "  'between',\n",
              "  'us',\n",
              "  'and',\n",
              "  'mexicoin',\n",
              "  'the',\n",
              "  '1920s',\n",
              "  'hookworm',\n",
              "  'eradication',\n",
              "  'reached',\n",
              "  'the',\n",
              "  'caribbean',\n",
              "  'and',\n",
              "  'latin',\n",
              "  'america',\n",
              "  'where',\n",
              "  'great',\n",
              "  'mortality',\n",
              "  'was',\n",
              "  'reported',\n",
              "  'among',\n",
              "  'people',\n",
              "  'in',\n",
              "  'the',\n",
              "  'west',\n",
              "  'indies',\n",
              "  'towards',\n",
              "  'the',\n",
              "  'end',\n",
              "  'of',\n",
              "  'the',\n",
              "  '18th',\n",
              "  'century',\n",
              "  'as',\n",
              "  'well',\n",
              "  'as',\n",
              "  'through',\n",
              "  'descriptions',\n",
              "  'sent',\n",
              "  'from',\n",
              "  'brazil',\n",
              "  'and',\n",
              "  'various',\n",
              "  'other',\n",
              "  'tropical',\n",
              "  'and',\n",
              "  'subtropical',\n",
              "  'regions',\n",
              "  'treatments',\n",
              "  'treatment',\n",
              "  'in',\n",
              "  'the',\n",
              "  'early',\n",
              "  '20th',\n",
              "  'century',\n",
              "  'relied',\n",
              "  'on',\n",
              "  'the',\n",
              "  'use',\n",
              "  'of',\n",
              "  'epsom',\n",
              "  'salt',\n",
              "  'to',\n",
              "  'reduce',\n",
              "  'protective',\n",
              "  'mucus',\n",
              "  'followed',\n",
              "  'by',\n",
              "  'thymol',\n",
              "  'to',\n",
              "  'kill',\n",
              "  'the',\n",
              "  'worms',\n",
              "  'by',\n",
              "  'the',\n",
              "  '1940s',\n",
              "  'tetrachloroethylene',\n",
              "  'was',\n",
              "  'the',\n",
              "  'leading',\n",
              "  'method'],\n",
              " 'text2_tokens': ['spinraza',\n",
              "  'access',\n",
              "  'by',\n",
              "  'country',\n",
              "  'treatsma',\n",
              "  '18',\n",
              "  'october',\n",
              "  '2018',\n",
              "  'retrieved',\n",
              "  '20190528']}"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_dataset['train'][0]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data loader\n",
        "\n",
        "We gonna make dataloader.  Inside here, we need to make two types of embeddings: **token embedding** and **segment embedding**\n",
        "\n",
        "1. **Token embedding** - Given “The cat is walking. The dog is barking”, we add [CLS] and [SEP] >> “[CLS] the cat is walking [SEP] the dog is barking”. \n",
        "\n",
        "2. **Segment embedding**\n",
        "A segment embedding separates two sentences, i.e., [0 0 0 0 1 1 1 1 ]\n",
        "\n",
        "3. **Masking**\n",
        "As mentioned in the original paper, BERT randomly assigns masks to 15% of the sequence. In this 15%, 80% is replaced with masks, while 10% is replaced with random tokens, and the rest 10% is left as is.  Here we specified `max_pred` \n",
        "\n",
        "4. **Padding**\n",
        "Once we mask, we will add padding. For simplicity, here we padded until some specified `max_len`. \n",
        "\n",
        "Note:  `positive` and `negative` are just simply counts to keep track of the batch size.  `positive` refers to two sentences that are really next to one another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Preparation and DataLoader Creation\n",
        "\n",
        "The provided code prepares the data for training a model. Here's a summary of the process:\n",
        "\n",
        "1. **Imports**: Necessary libraries such as `torch`, `tqdm`, and `numpy` are imported, along with `DataLoader` and `Dataset` from `torch.utils.data`.\n",
        "\n",
        "2. **Batch Creation Function**: The `make_batch` function creates batches of data. It tokenizes the text, adds special tokens, generates segment embeddings, predicts mask positions, and pads the sequences to a maximum length.\n",
        "\n",
        "3. **Custom Collate Function**: The `custom_collate_fn` function defines how to collate the batches, ensuring that the tensors are stacked properly.\n",
        "\n",
        "4. **Parameters**: Parameters such as batch size, maximum mask count, and maximum sequence length are defined.\n",
        "\n",
        "5. **Data Preparation**: The `make_batch` function is applied to both the training and validation datasets, producing batches of preprocessed data.\n",
        "\n",
        "6. **DataLoaders**: DataLoader objects are created for both the training and validation data, specifying batch size, shuffling for the training set, and using the custom collate function.\n",
        "\n",
        "7. **Example Usage**: An example of how to iterate over one batch from the training DataLoader is demonstrated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 85/85 [00:00<00:00, 374.95it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 575.46it/s]\n",
            "100%|██████████| 15/15 [00:00<00:00, 531.42it/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Assuming vocab and transformed_dataset are already defined and loaded\n",
        "\n",
        "def make_batch(dataset, vocab, max_mask, max_len):\n",
        "    data = []\n",
        "    \n",
        "    for example in tqdm(dataset):\n",
        "        # Transform the list of tokens to list of token indices based on vocab\n",
        "        tokens_a = [vocab[token] if token in vocab else vocab['[UNK]'] for token in example['text1_tokens']]\n",
        "        tokens_b = [vocab[token] if token in vocab else vocab['[UNK]'] for token in example['text2_tokens']]\n",
        "\n",
        "        # 1. Token embedding - add CLS and SEP\n",
        "        input_ids = [vocab['[CLS]']] + tokens_a + [vocab['[SEP]']] + tokens_b + [vocab['[SEP]']]\n",
        "\n",
        "        # 2. Segment embedding - which sentence is 0 and 1\n",
        "        segment_ids = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
        "\n",
        "        # Ensure length does not exceed max_len\n",
        "        input_ids = input_ids[:max_len]\n",
        "        segment_ids = segment_ids[:max_len]\n",
        "\n",
        "        # 3. Predicted mask positions\n",
        "        n_pred = min(max_mask, max(1, int(round(len(input_ids) * 0.15))))\n",
        "        candidates_masked_pos = [i for i, token in enumerate(input_ids) if token != vocab['[CLS]'] and token != vocab['[SEP]']]\n",
        "        np.random.shuffle(candidates_masked_pos)\n",
        "        masked_tokens, masked_pos = [], []\n",
        "\n",
        "        for pos in candidates_masked_pos[:n_pred]:\n",
        "            masked_pos.append(pos)\n",
        "            masked_tokens.append(input_ids[pos])\n",
        "            rand_val = np.random.random()\n",
        "            if rand_val < 0.1:\n",
        "                input_ids[pos] = vocab[vocab.get_itos()[np.random.randint(5, len(vocab) - 1)]]\n",
        "            elif rand_val < 0.8:\n",
        "                input_ids[pos] = vocab['[MASK]']\n",
        "\n",
        "        # 4. Pad the sentences and masks to max_len\n",
        "        n_pad = max_len - len(input_ids)\n",
        "        input_ids.extend([vocab['[PAD]']] * n_pad)\n",
        "        segment_ids.extend([0] * n_pad)\n",
        "\n",
        "        n_pad = max_mask - len(masked_tokens)\n",
        "        masked_tokens.extend([0] * n_pad)\n",
        "        masked_pos.extend([0] * n_pad)\n",
        "\n",
        "        instance = [input_ids, segment_ids, masked_tokens, masked_pos, [int(example['isNext'])]]\n",
        "        instance = [torch.LongTensor(i) for i in instance]\n",
        "        data.append(instance)\n",
        "        \n",
        "    return data\n",
        "\n",
        "def custom_collate_fn(batch):\n",
        "    input_ids = torch.stack([item[0] for item in batch])\n",
        "    segment_ids = torch.stack([item[1] for item in batch])\n",
        "    masked_tokens = torch.stack([item[2] for item in batch])\n",
        "    masked_pos = torch.stack([item[3] for item in batch])\n",
        "    isNext = torch.stack([item[4] for item in batch])\n",
        "    return input_ids, segment_ids, masked_tokens, masked_pos, isNext\n",
        "\n",
        "# Parameters\n",
        "batch_size = 16\n",
        "max_mask = 5\n",
        "max_len = 512\n",
        "\n",
        "# Prepare the data\n",
        "train_data = make_batch(tokenized_dataset['train'], vocab, max_mask, max_len)\n",
        "val_data = make_batch(tokenized_dataset['validation'], vocab, max_mask, max_len)\n",
        "test_data = make_batch(tokenized_dataset['test'], vocab, max_mask, max_len)\n",
        "\n",
        "# DataLoaders\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn)\n",
        "val_loader = DataLoader(val_data, batch_size=batch_size, collate_fn=custom_collate_fn)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size, collate_fn=custom_collate_fn)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Model\n",
        "\n",
        "Recall that BERT only uses the encoder.\n",
        "\n",
        "BERT has the following components:\n",
        "\n",
        "- Embedding layers\n",
        "- Attention Mask\n",
        "- Encoder layer\n",
        "- Multi-head attention\n",
        "- Scaled dot product attention\n",
        "- Position-wise feed-forward network\n",
        "- BERT (assembling all the components)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Embedding\n",
        "\n",
        "<img src = \"./figures/BERT_embed.png\" width=500>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Embedding Module\n",
        "\n",
        "The provided code defines an `Embedding` class, which serves as an embedding layer incorporating token, positional, and segment embeddings. Here's a summary of the module:\n",
        "\n",
        "- **Class**: `Embedding(nn.Module)`\n",
        "\n",
        "- **Initialization**:\n",
        "  - The constructor `__init__` initializes the embedding layers:\n",
        "    - `tok_embed`: Token embedding layer initialized with an embedding matrix of size `(vocab_size, d_model)`.\n",
        "    - `pos_embed`: Positional embedding layer initialized with an embedding matrix of size `(max_len, d_model)`, where `max_len` represents the maximum sequence length.\n",
        "    - `seg_embed`: Segment (or token type) embedding layer initialized with an embedding matrix of size `(n_segments, d_model)`.\n",
        "    - `norm`: Layer normalization applied to the final embedding.\n",
        "    - `device`: The device (e.g., CPU or GPU) on which the operations will be performed.\n",
        "\n",
        "- **Forward Pass**:\n",
        "  - The `forward` method takes input tokens `x` and segment embeddings `seg`.\n",
        "  - It calculates the positional embeddings based on the sequence length.\n",
        "  - It adds the token, positional, and segment embeddings together.\n",
        "  - Layer normalization is applied to the combined embeddings.\n",
        "  - The normalized embeddings are returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Embedding(nn.Module):\n",
        "    def __init__(self, vocab_size, max_len, n_segments, d_model, device):\n",
        "        super(Embedding, self).__init__()\n",
        "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
        "        self.pos_embed = nn.Embedding(max_len, d_model)      # position embedding\n",
        "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, x, seg):\n",
        "        #x, seg: (bs, len)\n",
        "        seq_len = x.size(1)\n",
        "        pos = torch.arange(seq_len, dtype=torch.long).to(self.device)\n",
        "        pos = pos.unsqueeze(0).expand_as(x)  # (len,) -> (bs, len)\n",
        "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
        "        return self.norm(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Attention mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "The provided code defines a function `get_attn_pad_mask` to create an attention mask for padding tokens. Here's a summary:\n",
        "\n",
        "- **Function**: `get_attn_pad_mask(seq_q, seq_k, device)`\n",
        "\n",
        "- **Arguments**:\n",
        "  - `seq_q`: Input sequence of queries.\n",
        "  - `seq_k`: Input sequence of keys.\n",
        "  - `device`: The device (e.g., CPU or GPU) on which the operations will be performed.\n",
        "\n",
        "- **Functionality**:\n",
        "  - It determines the padding tokens in the input sequence (`seq_k`) by checking if the token index is zero (which typically represents a PAD token).\n",
        "  - It creates a mask of shape `(batch_size, len_q, len_k)`, where `len_q` and `len_k` are the lengths of the query and key sequences, respectively.\n",
        "  - The mask is expanded along the batch dimension to match the batch size of the input sequences.\n",
        "\n",
        "- **Return**:\n",
        "  - Returns the attention mask for padding tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {
        "id": "s1PGksqBNuZM"
      },
      "outputs": [],
      "source": [
        "def get_attn_pad_mask(seq_q, seq_k, device):\n",
        "    batch_size, len_q = seq_q.size()\n",
        "    batch_size, len_k = seq_k.size()\n",
        "    # eq(zero) is PAD token\n",
        "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1).to(device)  # batch_size x 1 x len_k(=len_q), one is masking\n",
        "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Testing the attention mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([16, 512, 512])\n"
          ]
        }
      ],
      "source": [
        "print(get_attn_pad_mask(input_ids, input_ids, 'cpu').shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Encoder\n",
        "\n",
        "The encoder has two main components: \n",
        "\n",
        "- Multi-head Attention\n",
        "- Position-wise feed-forward network\n",
        "\n",
        "First let's make the wrapper called `EncoderLayer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Encoder Layer Module\n",
        "\n",
        "The provided code defines an `EncoderLayer` class, representing one layer in the encoder of a transformer model. Here's a summary:\n",
        "\n",
        "- **Class**: `EncoderLayer(nn.Module)`\n",
        "\n",
        "- **Initialization**:\n",
        "  - The constructor `__init__` initializes the encoder layer with parameters:\n",
        "    - `n_heads`: Number of attention heads.\n",
        "    - `d_model`: Dimensionality of the model.\n",
        "    - `d_ff`: Dimensionality of the feed-forward layer.\n",
        "    - `d_k`: Dimensionality of the key vectors.\n",
        "    - `device`: The device (e.g., CPU or GPU) on which the operations will be performed.\n",
        "  - It creates two sub-modules:\n",
        "    - `enc_self_attn`: Multi-head self-attention module initialized with the provided parameters.\n",
        "    - `pos_ffn`: Position-wise feed-forward network module initialized with the provided dimensionality.\n",
        "\n",
        "- **Forward Pass**:\n",
        "  - The `forward` method takes encoder inputs (`enc_inputs`) and self-attention mask (`enc_self_attn_mask`).\n",
        "  - It applies multi-head self-attention to the inputs using the `enc_self_attn` module.\n",
        "  - The outputs of the self-attention module are then passed through the position-wise feed-forward network (`pos_ffn`).\n",
        "  - The final encoder outputs and attention weights are returned."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, n_heads, d_model, d_ff, d_k, device):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.enc_self_attn = MultiHeadAttention(n_heads, d_model, d_k, device)\n",
        "        self.pos_ffn       = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "    def forward(self, enc_inputs, enc_self_attn_mask):\n",
        "        enc_outputs, attn = self.enc_self_attn(enc_inputs, enc_inputs, enc_inputs, enc_self_attn_mask) # enc_inputs to same Q,K,V\n",
        "        enc_outputs = self.pos_ffn(enc_outputs) # enc_outputs: [batch_size x len_q x d_model]\n",
        "        return enc_outputs, attn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's define the scaled dot attention, to be used inside the multihead attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Scaled Dot-Product Attention Module\n",
        "\n",
        "The provided code defines a `ScaledDotProductAttention` class, representing the scaled dot-product attention mechanism used in transformer models. Here's a summary:\n",
        "\n",
        "- **Class**: `ScaledDotProductAttention(nn.Module)`\n",
        "\n",
        "- **Initialization**:\n",
        "  - The constructor `__init__` initializes the attention mechanism with the dimensionality of the key vectors (`d_k`) and the device on which operations will be performed (`device`).\n",
        "  - It calculates the scale factor for scaling the dot-product scores.\n",
        "\n",
        "- **Forward Pass**:\n",
        "  - The `forward` method takes query (`Q`), key (`K`), and value (`V`) tensors, along with an attention mask (`attn_mask`).\n",
        "  - It calculates the dot-product of query and key tensors and scales it by the square root of the dimensionality of the key vectors.\n",
        "  - The attention scores are masked using the provided attention mask.\n",
        "  - The masked scores are passed through a softmax function to obtain attention weights.\n",
        "  - The context vector is calculated by weighted summing the values with the attention weights.\n",
        "  - The context vector and attention weights are returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, d_k, device):\n",
        "        super(ScaledDotProductAttention, self).__init__()\n",
        "        self.scale = torch.sqrt(torch.FloatTensor([d_k])).to(device)\n",
        "\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) / self.scale # scores : [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        scores.masked_fill_(attn_mask, -1e9) # Fills elements of self tensor with value where mask is one.\n",
        "        attn = nn.Softmax(dim=-1)(scores)\n",
        "        context = torch.matmul(attn, V)\n",
        "        return context, attn "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the Multiheadattention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Multi-Head Attention Module\n",
        "\n",
        "The provided code defines a `MultiHeadAttention` class, which implements the multi-head attention mechanism in transformer models. Here's a summary:\n",
        "\n",
        "- **Class**: `MultiHeadAttention(nn.Module)`\n",
        "\n",
        "- **Initialization**:\n",
        "  - The constructor `__init__` initializes the multi-head attention mechanism with parameters:\n",
        "    - `n_heads`: Number of attention heads.\n",
        "    - `d_model`: Dimensionality of the model.\n",
        "    - `d_k`: Dimensionality of the key vectors.\n",
        "    - `device`: The device (e.g., CPU or GPU) on which the operations will be performed.\n",
        "  - It creates linear transformation layers (`W_Q`, `W_K`, `W_V`) to project input queries, keys, and values into the multi-head space.\n",
        "\n",
        "- **Forward Pass**:\n",
        "  - The `forward` method takes query (`Q`), key (`K`), and value (`V`) tensors, along with an attention mask (`attn_mask`).\n",
        "  - It projects the input tensors into the multi-head space using linear transformations and splits them into multiple heads.\n",
        "  - The scaled dot-product attention is applied to each head.\n",
        "  - The context vectors from all heads are concatenated and linearly transformed back to the original dimensionality.\n",
        "  - Layer normalization is applied to the output, and the residual connection is added.\n",
        "  - The output and attention weights are returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [],
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, n_heads, d_model, d_k, device):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.n_heads = n_heads\n",
        "        self.d_model = d_model\n",
        "        self.d_k = d_k\n",
        "        self.d_v = d_k\n",
        "        self.W_Q = nn.Linear(d_model, d_k * n_heads)\n",
        "        self.W_K = nn.Linear(d_model, d_k * n_heads)\n",
        "        self.W_V = nn.Linear(d_model, self.d_v * n_heads)\n",
        "        self.device = device\n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # q: [batch_size x len_q x d_model], k: [batch_size x len_k x d_model], v: [batch_size x len_k x d_model]\n",
        "        residual, batch_size = Q, Q.size(0)\n",
        "        # (B, S, D) -proj-> (B, S, D) -split-> (B, S, H, W) -trans-> (B, H, S, W)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # q_s: [batch_size x n_heads x len_q x d_k]\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)  # k_s: [batch_size x n_heads x len_k x d_k]\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)  # v_s: [batch_size x n_heads x len_k x d_v]\n",
        "\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) # attn_mask : [batch_size x n_heads x len_q x len_k]\n",
        "\n",
        "        # context: [batch_size x n_heads x len_q x d_v], attn: [batch_size x n_heads x len_q(=len_k) x len_k(=len_q)]\n",
        "        context, attn = ScaledDotProductAttention(self.d_k, self.device)(q_s, k_s, v_s, attn_mask)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_heads * self.d_v) # context: [batch_size x len_q x n_heads * d_v]\n",
        "        output = nn.Linear(self.n_heads * self.d_v, self.d_model, device=self.device)(context)\n",
        "        return nn.LayerNorm(self.d_model, device=self.device)(output + residual), attn # output: [batch_size x len_q x d_model]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is the PoswiseFeedForwardNet."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Position-wise Feed-Forward Network Module\n",
        "\n",
        "The provided code defines a `PoswiseFeedForwardNet` class, which implements the position-wise feed-forward network used in transformer models. Here's a summary:\n",
        "\n",
        "- **Class**: `PoswiseFeedForwardNet(nn.Module)`\n",
        "\n",
        "- **Initialization**:\n",
        "  - The constructor `__init__` initializes the feed-forward network with parameters:\n",
        "    - `d_model`: Dimensionality of the input and output tensors.\n",
        "    - `d_ff`: Dimensionality of the hidden layer.\n",
        "  - It creates two linear transformation layers (`fc1`, `fc2`) with appropriate input and output dimensions.\n",
        "\n",
        "- **Forward Pass**:\n",
        "  - The `forward` method takes input tensor `x`.\n",
        "  - It applies the first linear transformation followed by the GELU activation function (`F.gelu`) and then the second linear transformation.\n",
        "  - The output tensor is returned.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(d_model, d_ff)\n",
        "        self.fc2 = nn.Linear(d_ff, d_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (batch_size, len_seq, d_model) -> (batch_size, len_seq, d_ff) -> (batch_size, len_seq, d_model)\n",
        "        return self.fc2(F.gelu(self.fc1(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.4 Putting them together"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BERT Model\n",
        "\n",
        "The provided code defines a `BERT` class, which represents a BERT (Bidirectional Encoder Representations from Transformers) model. Here's a summary:\n",
        "\n",
        "- **Class**: `BERT(nn.Module)`\n",
        "\n",
        "- **Initialization**:\n",
        "  - The constructor `__init__` initializes the BERT model with parameters such as the number of layers, number of attention heads, dimensionality of the model, etc.\n",
        "  - It initializes the embedding layer, encoder layers, classification layers, and decoder.\n",
        "\n",
        "- **Forward Pass**:\n",
        "  - The `forward` method takes input IDs, segment IDs, and masked positions.\n",
        "  - It passes the inputs through the embedding layer and multiple encoder layers.\n",
        "  - It predicts the next sentence and masked tokens.\n",
        "  - The outputs of both tasks are returned.\n",
        "\n",
        "- **Helper Method**:\n",
        "  - The `get_last_hidden_state` method takes input IDs and segment IDs.\n",
        "  - It passes the inputs through the embedding layer and multiple encoder layers.\n",
        "  - It returns the last hidden state of the encoder layers.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {
        "id": "OZ0TJ84W4SZw"
      },
      "outputs": [],
      "source": [
        "class BERT(nn.Module):\n",
        "    def __init__(self, n_layers, n_heads, d_model, d_ff, d_k, n_segments, vocab_size, max_len, device):\n",
        "        super(BERT, self).__init__()\n",
        "        self.params = {'n_layers': n_layers, 'n_heads': n_heads, 'd_model': d_model,\n",
        "                       'd_ff': d_ff, 'd_k': d_k, 'n_segments': n_segments,\n",
        "                       'vocab_size': vocab_size, 'max_len': max_len}\n",
        "        self.embedding = Embedding(vocab_size, max_len, n_segments, d_model, device)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(n_heads, d_model, d_ff, d_k, device) for _ in range(n_layers)])\n",
        "        self.fc = nn.Linear(d_model, d_model)\n",
        "        self.activ = nn.Tanh()\n",
        "        self.linear = nn.Linear(d_model, d_model)\n",
        "        self.norm = nn.LayerNorm(d_model)\n",
        "        self.classifier = nn.Linear(d_model, 2)\n",
        "        # decoder is shared with embedding layer\n",
        "        embed_weight = self.embedding.tok_embed.weight\n",
        "        n_vocab, n_dim = embed_weight.size()\n",
        "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
        "        self.decoder.weight = embed_weight\n",
        "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, input_ids, segment_ids, masked_pos):\n",
        "        output = self.embedding(input_ids, segment_ids)\n",
        "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
        "        for layer in self.layers:\n",
        "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
        "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
        "        \n",
        "        # 1. predict next sentence\n",
        "        # it will be decided by first token(CLS)\n",
        "        h_pooled   = self.activ(self.fc(output[:, 0])) # [batch_size, d_model]\n",
        "        logits_nsp = self.classifier(h_pooled) # [batch_size, 2]\n",
        "\n",
        "        # 2. predict the masked token\n",
        "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
        "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
        "        h_masked  = self.norm(F.gelu(self.linear(h_masked)))\n",
        "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
        "\n",
        "        return logits_lm, logits_nsp\n",
        "    \n",
        "    def get_last_hidden_state(self, input_ids, segment_ids):\n",
        "        output = self.embedding(input_ids, segment_ids)\n",
        "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids, self.device)\n",
        "        for layer in self.layers:\n",
        "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting Device and Seed\n",
        "\n",
        "- **Device Selection**:\n",
        "  - The code checks if CUDA (GPU) is available. If it is, it sets the device to 'cuda'; otherwise, it sets it to 'cpu'.\n",
        "  - This ensures that the model and computations will be performed on the available hardware resource (GPU if available, otherwise CPU).\n",
        "\n",
        "- **Setting Seed for Reproducibility**:\n",
        "  - The code sets a manual seed (`SEED`) to ensure reproducibility of results across multiple runs.\n",
        "  - Additionally, it enables deterministic behavior of the CuDNN backend for CUDA operations, further enhancing reproducibility.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UAG3SEP4UbU",
        "outputId": "bc6f202f-df37-4fac-843c-fb86bdb777b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpu\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "\n",
        "#make our work comparable if restarted the kernel\n",
        "SEED = 1234\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT Model Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_layers = 6    # number of Encoder of Encoder Layer\n",
        "n_heads  = 8    # number of heads in Multi-Head Attention\n",
        "d_model  = 768  # Embedding Size\n",
        "d_ff = 768 * 4  # 4*d_model, FeedForward dimension\n",
        "d_k = d_v = 64  # dimension of K(=Q), V\n",
        "n_segments = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### BERT Model Initialization\n",
        "\n",
        "- The BERT model is initialized using the specified configuration parameters:\n",
        "  - Number of Encoder Layers: 6\n",
        "  - Number of Attention Heads: 8\n",
        "  - Embedding Size: 768\n",
        "  - FeedForward Dimension: 3072\n",
        "  - Dimension of K(=Q) and V: 64\n",
        "  - Number of Segments: 2\n",
        "  - Vocabulary Size: Determined by the length of the vocabulary\n",
        "  - Maximum Sequence Length: Determined by the maximum length of sequences\n",
        "  - Device: Determined by the availability of CUDA (GPU) or CPU\n",
        "  \n",
        "- The model is then moved to the selected device (CUDA if available, otherwise CPU) using `.to(device)`.\n",
        "\n",
        "- **Loss Function**:\n",
        "  - Cross-entropy loss (`nn.CrossEntropyLoss()`) is chosen as the criterion for training.\n",
        "\n",
        "- **Optimizer**:\n",
        "  - Adam optimizer (`optim.Adam`) is used with a learning rate of 5e-5, following the setting used in the BERT paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = BERT(n_layers, n_heads, d_model, d_ff, d_k, n_segments, len(vocab), max_len, device).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=5e-5)  # BERT paper used 5e-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "37073759\n"
          ]
        }
      ],
      "source": [
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(num_params)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Function\n",
        "\n",
        "The provided `train` function is used to train the BERT model. Here's a summary of its functionality:\n",
        "\n",
        "- **Input**:\n",
        "  - `model`: The BERT model to be trained.\n",
        "  - `data`: The DataLoader containing the training data.\n",
        "  - `optimizer`: The optimizer used for updating model parameters.\n",
        "  - `criterion`: The loss function used for calculating the loss.\n",
        "  - `device`: The device (CPU or GPU) where the model and data are located.\n",
        "\n",
        "- **Functionality**:\n",
        "  - Sets the model to training mode.\n",
        "  - Iterates over batches of data from the DataLoader.\n",
        "  - Zeroes the gradients of the optimizer.\n",
        "  - Transfers input data to the specified device.\n",
        "  - Computes the forward pass through the model to obtain predictions.\n",
        "  - Calculates the masked language model (MLM) loss and next sentence prediction (NSP) loss.\n",
        "  - Combines both losses and computes the total loss.\n",
        "  - Backpropagates the total loss and updates the model parameters using the optimizer.\n",
        "  - Returns the mean loss over all batches for the epoch.\n",
        "\n",
        "- **Note**:\n",
        "  - MLM loss is calculated based on the predicted masked tokens compared to the actual masked tokens.\n",
        "  - NSP loss is calculated based on the predicted next sentence classification compared to the actual next sentence labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 283,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, data, optimizer, criterion, device):\n",
        "    epoch_loss = []\n",
        "    model.train()\n",
        "\n",
        "    for input_ids, segment_ids, masked_tokens, masked_pos, isNext in tqdm(data, desc='Training: '):\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = input_ids.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        masked_tokens = masked_tokens.to(device)\n",
        "        masked_pos = masked_pos.to(device)\n",
        "        isNext = isNext.flatten().to(device)\n",
        "        logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)    \n",
        "        #logits_lm: (bs, max_mask, vocab_size) ==> (6, 5, 34)\n",
        "        #logits_nsp: (bs, yes/no) ==> (6, 2)\n",
        "\n",
        "        #1. mlm loss\n",
        "        #logits_lm.transpose: (bs, vocab_size, max_mask) vs. masked_tokens: (bs, max_mask)\n",
        "        loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
        "        loss_lm = (loss_lm.float()).mean()\n",
        "        #2. nsp loss\n",
        "        #logits_nsp: (bs, 2) vs. isNext: (bs, )\n",
        "        loss_nsp = criterion(logits_nsp, isNext) # for sentence classification\n",
        "        \n",
        "        #3. combine loss\n",
        "        loss = loss_lm + loss_nsp\n",
        "        epoch_loss.append(loss.item())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    return np.mean(epoch_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluation Function\n",
        "\n",
        "The provided `evaluate` function is used to evaluate the performance of the BERT model on the validation or test dataset. Here's a summary of its functionality:\n",
        "\n",
        "- **Input**:\n",
        "  - `model`: The BERT model to be evaluated.\n",
        "  - `data`: The DataLoader containing the evaluation data.\n",
        "  - `criterion`: The loss function used for calculating the loss.\n",
        "  - `device`: The device (CPU or GPU) where the model and data are located.\n",
        "\n",
        "- **Functionality**:\n",
        "  - Sets the model to evaluation mode.\n",
        "  - Iterates over batches of data from the DataLoader.\n",
        "  - Transfers input data to the specified device.\n",
        "  - Computes the forward pass through the model to obtain predictions.\n",
        "  - Calculates the masked language model (MLM) loss and next sentence prediction (NSP) loss.\n",
        "  - Combines both losses and computes the total loss.\n",
        "  - Returns the mean loss over all batches for the evaluation dataset.\n",
        "\n",
        "- **Note**:\n",
        "  - Similar to the `train` function, MLM loss and NSP loss are calculated based on the predicted masked tokens and next sentence classification compared to the actual values.\n",
        "  - The `torch.no_grad()` context manager is used to disable gradient calculation, speeding up computation and reducing memory cost during evaluation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 284,
      "metadata": {},
      "outputs": [],
      "source": [
        "def evaluate(model, data, criterion, device):\n",
        "    epoch_loss = []\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():  # set the 'requires_grad' to False to speed up computation and reduce memory cost\n",
        "        for input_ids, segment_ids, masked_tokens, masked_pos, isNext in tqdm(data, desc='Evaluate: '):\n",
        "            input_ids = input_ids.to(device)\n",
        "            segment_ids = segment_ids.to(device)\n",
        "            masked_tokens = masked_tokens.to(device)\n",
        "            masked_pos = masked_pos.to(device)\n",
        "            isNext = isNext.flatten().to(device)\n",
        "            logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)    \n",
        "            #logits_lm: (bs, max_mask, vocab_size) ==> (6, 5, 34)\n",
        "            #logits_nsp: (bs, yes/no) ==> (6, 2)\n",
        "\n",
        "            #1. mlm loss\n",
        "            #logits_lm.transpose: (bs, vocab_size, max_mask) vs. masked_tokens: (bs, max_mask)\n",
        "            loss_lm = criterion(logits_lm.transpose(1, 2), masked_tokens) # for masked LM\n",
        "            loss_lm = (loss_lm.float()).mean()\n",
        "            #2. nsp loss\n",
        "            #logits_nsp: (bs, 2) vs. isNext: (bs, )\n",
        "            loss_nsp = criterion(logits_nsp, isNext) # for sentence classification\n",
        "            \n",
        "            #3. combine loss\n",
        "            loss = loss_lm + loss_nsp\n",
        "            epoch_loss.append(loss.item())\n",
        "\n",
        "    return np.mean(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [],
      "source": [
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Training Loop\n",
        "\n",
        "The provided code snippet trains the BERT model over a specified number of epochs and evaluates its performance on a validation dataset. Here's a summary of the training loop:\n",
        "\n",
        "- **Initialization**:\n",
        "  - The training loop is configured with parameters such as the number of epochs (`num_epoch`), the path to save the best model (`save_path`), and a learning rate scheduler (`lr_scheduler`) to adjust the learning rate based on validation loss.\n",
        "\n",
        "- **Training Loop**:\n",
        "  - For each epoch, the loop iterates over the training DataLoader (`train_loader`) and evaluates the model's performance on the validation DataLoader (`val_loader`).\n",
        "  - Training and evaluation losses are computed using the `train` and `evaluate` functions, respectively.\n",
        "  - The learning rate scheduler (`lr_scheduler`) adjusts the learning rate based on the validation loss.\n",
        "  - Training and validation losses are recorded for plotting.\n",
        "\n",
        "- **Model Saving**:\n",
        "  - The model is saved only if the validation loss improves compared to the previous best validation loss.\n",
        "  - The model's parameters and state are saved to the specified file path (`save_path`).\n",
        "\n",
        "- **Printed Information**:\n",
        "  - For each epoch, the training time, training loss, and validation loss are printed.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [02:43<00:00, 27.31s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:07<00:00,  7.38s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 2m 51s\n",
            "\tTrain Loss: 23.529\n",
            "\t Val. Loss: 27.009\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [02:38<00:00, 26.49s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:07<00:00,  7.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 02 | Time: 2m 46s\n",
            "\tTrain Loss: 12.805\n",
            "\t Val. Loss: 9.155\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [02:48<00:00, 28.14s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:07<00:00,  7.28s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 03 | Time: 2m 56s\n",
            "\tTrain Loss: 8.529\n",
            "\t Val. Loss: 7.790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [02:27<00:00, 24.64s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:07<00:00,  7.08s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 04 | Time: 2m 34s\n",
            "\tTrain Loss: 10.065\n",
            "\t Val. Loss: 6.322\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [02:31<00:00, 25.22s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:06<00:00,  6.98s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 05 | Time: 2m 38s\n",
            "\tTrain Loss: 6.418\n",
            "\t Val. Loss: 7.046\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [02:18<00:00, 23.02s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:07<00:00,  7.07s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 06 | Time: 2m 25s\n",
            "\tTrain Loss: 8.742\n",
            "\t Val. Loss: 6.443\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [02:26<00:00, 24.47s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:07<00:00,  7.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 07 | Time: 2m 34s\n",
            "\tTrain Loss: 7.089\n",
            "\t Val. Loss: 5.904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [03:06<00:00, 31.01s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:07<00:00,  7.24s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 08 | Time: 3m 13s\n",
            "\tTrain Loss: 5.906\n",
            "\t Val. Loss: 5.408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [02:34<00:00, 25.72s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:06<00:00,  6.92s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 09 | Time: 2m 41s\n",
            "\tTrain Loss: 5.686\n",
            "\t Val. Loss: 4.698\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 6/6 [02:26<00:00, 24.44s/it]\n",
            "Evaluate: 100%|██████████| 1/1 [00:07<00:00,  7.77s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 10 | Time: 2m 34s\n",
            "\tTrain Loss: 4.103\n",
            "\t Val. Loss: 4.110\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "save_path = './model/bert_best_model.pt'\n",
        "num_epoch = 10\n",
        "\n",
        "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=0)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(num_epoch):\n",
        "    start_time = time.time()\n",
        "    train_loss = train(model, train_loader, optimizer, criterion, device)\n",
        "    val_loss = evaluate(model, val_loader, criterion, device)\n",
        "    lr_scheduler.step(val_loss)\n",
        "\n",
        "    #for plotting\n",
        "    train_losses.append(train_loss)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    end_time = time.time()\n",
        "        \n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    # save the model only when its validation loss is lower than all its predecessors\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save([model.params, model.state_dict()], save_path)  # save the model's parameters and state to a file\n",
        "\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
        "    print(f'\\t Val. Loss: {val_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Training Loss for BERT Scratch Model: 9.2872\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average loss\n",
        "average_loss = sum(train_losses) / len(train_losses)\n",
        "\n",
        "# Display the average loss\n",
        "print(\"Average Training Loss for BERT Scratch Model:\", average_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Validation Loss for BERT Scratch Model: 8.3885\n"
          ]
        }
      ],
      "source": [
        "# Calculate the average validation loss\n",
        "average_val_loss = sum(val_losses) / len(val_losses)\n",
        "\n",
        "# Display the average validation loss\n",
        "print(\"Average Validation Loss for BERT Scratch Model:\", average_val_loss)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Precision: 0.2178, Recall: 0.4667, F1 Score: 0.2970, Avg Test Loss: 0.7880\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/shafisourov/anaconda3/envs/nlu/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import torch\n",
        "\n",
        "def evaluate_and_predict(model, data_loader, criterion, device):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    true_labels = []\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for input_ids, segment_ids, masked_tokens, masked_pos, isNext in data_loader:\n",
        "            input_ids = input_ids.to(device)\n",
        "            segment_ids = segment_ids.to(device)\n",
        "            masked_pos = masked_pos.to(device)\n",
        "            isNext = isNext.flatten().to(device)\n",
        "            \n",
        "            # Get model predictions\n",
        "            logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
        "            # Here we focus on next sentence prediction task (isNext classification)\n",
        "            logits = logits_nsp  # Assuming logits_nsp is the output for the next sentence prediction task\n",
        "\n",
        "            # Calculate loss for tracking (optional)\n",
        "            loss = criterion(logits, isNext)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Convert logits to probabilities and then to class predictions\n",
        "            probs = torch.nn.functional.softmax(logits, dim=1)\n",
        "            preds = torch.argmax(probs, dim=1)\n",
        "            \n",
        "            # Collect predictions and true labels\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            true_labels.extend(isNext.cpu().numpy())\n",
        "\n",
        "    # Calculate Precision, Recall, and F1 Score\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(true_labels, predictions, average='weighted')\n",
        "    avg_loss = total_loss / len(data_loader)\n",
        "\n",
        "    return precision, recall, f1, avg_loss\n",
        "\n",
        "# Using the function to calculate metrics and average test loss\n",
        "precision, recall, f1, avg_test_loss = evaluate_and_predict(model, test_loader, criterion, device)\n",
        "\n",
        "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}, Avg Test Loss: {avg_test_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loss Visualization\n",
        "\n",
        "The provided code snippet visualizes the training and validation losses over the training epochs using matplotlib. Here's a summary of the visualization:\n",
        "\n",
        "- **Initialization**:\n",
        "  - Matplotlib is imported (`import matplotlib.pyplot as plt`).\n",
        "\n",
        "- **Visualization**:\n",
        "  - A figure (`fig`) is created with a specific size (5x3) using `plt.figure(figsize=(5, 3))`.\n",
        "  - An axis (`ax`) is added to the figure using `fig.add_subplot(1, 1, 1)`.\n",
        "  - The training and validation losses are plotted using `ax.plot(train_losses, label='train loss')` and `ax.plot(val_losses, label='validation loss')`, respectively.\n",
        "  - A legend is added to distinguish between the training and validation losses using `plt.legend()`.\n",
        "  - The x-axis label is set to 'updates' and the y-axis label is set to 'loss' using `ax.set_xlabel('updates')` and `ax.set_ylabel('loss')`, respectively.\n",
        "\n",
        "This visualization helps in monitoring the training progress and identifying potential overfitting or underfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'loss')"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig = plt.figure(figsize=(5, 3))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.plot(train_losses, label = 'train loss')\n",
        "ax.plot(val_losses, label = 'validation loss')\n",
        "plt.legend()\n",
        "ax.set_xlabel('updates')\n",
        "ax.set_ylabel('loss')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Inference\n",
        "\n",
        "Since our dataset is very small, it won't work very well, but just for the sake of demonstration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Prediction Summary\n",
        "\n",
        "The provided code snippet demonstrates how to use the trained BERT model to predict masked tokens and the next sentence prediction (isNext) on a validation dataset. Here's a summary of the prediction process:\n",
        "\n",
        "1. **Initialization**:\n",
        "   - The model, vocabulary, and parameters are loaded from saved files.\n",
        "   - The model is moved to the appropriate device (GPU if available, otherwise CPU).\n",
        "\n",
        "2. **Prediction Process**:\n",
        "   - For each batch in the validation DataLoader (`val_loader`), a single data point is randomly selected.\n",
        "   - The selected data point is processed using the `process_data_point` function, which takes the input data and performs predictions.\n",
        "   - For masked tokens prediction:\n",
        "     - The model predicts masked tokens using the provided input data.\n",
        "     - The predicted masked tokens are printed alongside the actual masked tokens.\n",
        "   - For next sentence prediction (isNext):\n",
        "     - The model predicts whether the next sentence is true or false based on the provided input data.\n",
        "     - The predicted isNext label is printed alongside the actual isNext label.\n",
        "\n",
        "3. **Output**:\n",
        "   - The predicted masked tokens and isNext label are printed for visualization.\n",
        "   - Any errors that occur during the prediction process are caught and displayed.\n",
        "\n",
        "This process helps in understanding how the trained BERT model performs on unseen data and provides insights into its predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "from model_class import *\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "save_path = './model/bert_best_model.pt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# load the model and all its hyperparameters\n",
        "params, state = torch.load(save_path)\n",
        "model = BERT(**params, device=device).to(device)\n",
        "model.load_state_dict(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "vocab = torch.load('./model/vocab.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "93"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'p', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[MASK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', ')', '[MASK]', '(', '[UNK]', ')', '1', '[UNK]', '[UNK]', '(', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '1', '[UNK]', '[UNK]', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[SEP]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'j', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[MASK]', '[UNK]', '[UNK]', 'a', '[MASK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', ')', '[SEP]']\n",
            "masked tokens (words) :  ['[UNK]', '(', '[UNK]', '[UNK]', '[UNK]']\n",
            "masked tokens list :  [4, 31, 4, 4, 4]\n",
            "predicted masked tokens (words) :  ['[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]']\n",
            "predicted masked tokens list :  [4, 4, 4, 4, 4]\n",
            "0\n",
            "isNext :  False\n",
            "predict isNext :  False\n"
          ]
        }
      ],
      "source": [
        "# Predict mask tokens ans isNext\n",
        "for input_ids, segment_ids, masked_tokens, masked_pos, isNext in val_loader:\n",
        "    break\n",
        "\n",
        "idx = 2\n",
        "input_ids = input_ids[idx].reshape(1, -1).to(device)\n",
        "segment_ids = segment_ids[idx].reshape(1, -1).to(device)\n",
        "masked_tokens = masked_tokens[idx].reshape(1, -1).to(device)\n",
        "masked_pos = masked_pos[idx].reshape(1, -1).to(device)\n",
        "isNext = isNext[idx].item()\n",
        "\n",
        "print([vocab.get_itos()[w.item()] for w in input_ids[0] if vocab.get_itos()[w.item()] != '[PAD]'])\n",
        "\n",
        "logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
        "#logits_lm:  (1, max_mask, vocab_size) ==> (1, 5, 34)\n",
        "#logits_nsp: (1, yes/no) ==> (1, 2)\n",
        "\n",
        "#predict masked tokens\n",
        "#max the probability along the vocab dim (2), [1] is the indices of the max, and [0] is the first value\n",
        "logits_lm = logits_lm.data.cpu().max(2)[1][0].data.numpy() \n",
        "#note that zero is padding we add to the masked_tokens\n",
        "print('masked tokens (words) : ',[vocab.get_itos()[pos.item()] for pos in masked_tokens[0] if pos.item() != 0])\n",
        "print('masked tokens list : ',[pos.item() for pos in masked_tokens[0] if pos.item() != 0])\n",
        "print('predicted masked tokens (words) : ',[vocab.get_itos()[pos.item()] for pos in logits_lm if pos.item() != 0])\n",
        "print('predicted masked tokens list : ', [pos for pos in logits_lm if pos.item() != 0])\n",
        "\n",
        "#predict nsp\n",
        "logits_nsp = logits_nsp.data.cpu().max(1)[1][0].data.numpy()\n",
        "print(logits_nsp)\n",
        "print('isNext : ', True if isNext else False)\n",
        "print('predict isNext : ', True if logits_nsp else False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['[CLS]', '[UNK]', '[UNK]', '(', '[UNK]', '[UNK]', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[MASK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[MASK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[MASK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[MASK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[MASK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[SEP]', '[UNK]', '[UNK]', '(', '[UNK]', ')', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '(', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', ')', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', 'a', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[SEP]']\n",
            "Masked tokens (words): ['[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]']\n",
            "Predicted masked tokens (words): ['[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]']\n",
            "isNext: False\n",
            "Predicted isNext: False\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "def process_data_point(idx, input_ids, segment_ids, masked_tokens, masked_pos, isNext, device, model, vocab):\n",
        "    \"\"\"\n",
        "    Process a single data point and print the prediction results.\n",
        "    \"\"\"\n",
        "    # Reshape and send to device\n",
        "    input_ids = input_ids[idx].reshape(1, -1).to(device)\n",
        "    segment_ids = segment_ids[idx].reshape(1, -1).to(device)\n",
        "    masked_tokens = masked_tokens[idx].reshape(1, -1).to(device)\n",
        "    masked_pos = masked_pos[idx].reshape(1, -1).to(device)\n",
        "    isNext = isNext[idx].item()\n",
        "\n",
        "    print([vocab.get_itos()[w.item()] for w in input_ids[0] if vocab.get_itos()[w.item()] != '[PAD]'])\n",
        "\n",
        "    logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
        "\n",
        "    # Process language model logits\n",
        "    logits_lm = logits_lm.data.cpu().max(2)[1][0].data.numpy()\n",
        "    print('Masked tokens (words):', [vocab.get_itos()[pos.item()] for pos in masked_tokens[0] if pos.item() != 0])\n",
        "    print('Predicted masked tokens (words):', [vocab.get_itos()[pos.item()] for pos in logits_lm if pos.item() != 0])\n",
        "\n",
        "    # Process next sentence prediction logits\n",
        "    logits_nsp = logits_nsp.data.cpu().max(1)[1][0].data.numpy()\n",
        "    print('isNext:', True if isNext else False)\n",
        "    print('Predicted isNext:', True if logits_nsp else False)\n",
        "\n",
        "# Predict mask tokens and isNext\n",
        "try:\n",
        "    for input_ids, segment_ids, masked_tokens, masked_pos, isNext in val_loader:\n",
        "        # Randomly select an index from the batch\n",
        "        batch_size = input_ids.size(0)\n",
        "        idx = random.randint(0, batch_size - 1)\n",
        "\n",
        "        process_data_point(idx, input_ids, segment_ids, masked_tokens, masked_pos, isNext, device, model, vocab)\n",
        "        break  # Only process one batch for demonstration\n",
        "except Exception as e:\n",
        "    print(f\"Error processing batch: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text 1:\n",
            "  econometric studies have shown that this effect cannot be explained by a variety of alternative factors including differential trends across areas changing crop prices shifts in certain educational and health policies and the effect of malaria eradication no significant contemporaneous results were found for adults who should have benefited less from the intervention owing to their substantially lower (prior) infection rates the program nearly eradicated hookworm and would flourish afterward with new funding as the rockefeller foundation international health divisionthe rfs hookworm campaign in mexico showed how science and politics play a role in developing health policies it brought together government officials health officials public health workers rockefeller officials and the community this campaign was launched to eradicate hookworms in mexico although the campaign did not focus on longterm treatments it did set the terms of the relationship between mexico and the rockefeller foundation the scientific knowledge behind this campaign helped shape public health policies improved public health and built a strong relationship between us and mexicoin the 1920s hookworm eradication reached the caribbean and latin america where great mortality was reported among people in the west indies towards the end of the 18th century as well as through descriptions sent from brazil and various other tropical and subtropical regions treatments\n",
            "treatment in the early 20th century relied on the use of epsom salt to reduce protective mucus followed by thymol to kill the worms by the 1940s tetrachloroethylene was the leading method\n",
            "\n",
            "Original Text 2:\n",
            " \"spinraza access by country\" treatsma 18 october 2018 retrieved 20190528\n",
            "\n",
            "Are sentences next? No (Original)\n",
            "\n",
            "Predicted NSP: No\n",
            "\n",
            "NSP Score: 0.6417 (Confidence)\n"
          ]
        }
      ],
      "source": [
        "# The specific input example you provided\n",
        "input_example = {\n",
        "    'text1': ' econometric studies have shown that this effect cannot be explained by a variety of alternative factors including differential trends across areas changing crop prices shifts in certain educational and health policies and the effect of malaria eradication no significant contemporaneous results were found for adults who should have benefited less from the intervention owing to their substantially lower (prior) infection rates the program nearly eradicated hookworm and would flourish afterward with new funding as the rockefeller foundation international health divisionthe rfs hookworm campaign in mexico showed how science and politics play a role in developing health policies it brought together government officials health officials public health workers rockefeller officials and the community this campaign was launched to eradicate hookworms in mexico although the campaign did not focus on longterm treatments it did set the terms of the relationship between mexico and the rockefeller foundation the scientific knowledge behind this campaign helped shape public health policies improved public health and built a strong relationship between us and mexicoin the 1920s hookworm eradication reached the caribbean and latin america where great mortality was reported among people in the west indies towards the end of the 18th century as well as through descriptions sent from brazil and various other tropical and subtropical regions treatments\\ntreatment in the early 20th century relied on the use of epsom salt to reduce protective mucus followed by thymol to kill the worms by the 1940s tetrachloroethylene was the leading method',\n",
        "    'text2': '\"spinraza access by country\" treatsma 18 october 2018 retrieved 20190528',\n",
        "    'isNext': False\n",
        "}\n",
        "\n",
        "# Assuming 'tokenizer', 'vocab', and 'device' are already defined and loaded\n",
        "\n",
        "# Tokenize the input texts\n",
        "text1_tokens = tokenizer(input_example['text1'])\n",
        "text2_tokens = tokenizer(input_example['text2'])\n",
        "\n",
        "\n",
        "# Convert tokens to vocab indices\n",
        "tokens_a_idx = [vocab[token] if token in vocab else vocab['[UNK]'] for token in text1_tokens]\n",
        "tokens_b_idx = [vocab[token] if token in vocab else vocab['[UNK]'] for token in text2_tokens]\n",
        "\n",
        "# Prepare model inputs\n",
        "input_ids = [vocab['[CLS]']] + tokens_a_idx + [vocab['[SEP]']] + tokens_b_idx + [vocab['[SEP]']]\n",
        "segment_ids = [0] * (len(tokens_a_idx) + 2) + [1] * (len(tokens_b_idx) + 1)\n",
        "input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
        "segment_ids = torch.tensor(segment_ids).unsqueeze(0).to(device)\n",
        "masked_pos = torch.tensor([]).unsqueeze(0).to(device)  # No masked tokens in the inference example\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
        "\n",
        "# Predicted isNext flag and confidence score\n",
        "predicted_isNext = logits_nsp.argmax(dim=-1).item()\n",
        "confidence_score = torch.nn.functional.softmax(logits_nsp, dim=-1).max().item()\n",
        "predicted_isNext_text = \"Yes\" if predicted_isNext else \"No\"\n",
        "original_isNext = \"Yes\" if input_example['isNext'] else \"No\"\n",
        "\n",
        "# Display results\n",
        "print(\"Original Text 1:\\n\", input_example['text1'])\n",
        "print(\"\\nOriginal Text 2:\\n\", input_example['text2'])\n",
        "print(f\"\\nAre sentences next? {original_isNext} (Original)\")\n",
        "print(f\"\\nPredicted NSP: {predicted_isNext_text}\")\n",
        "print(f\"\\nNSP Score: {confidence_score:.4f} (Confidence)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text 1: traffic accidents are the most common form of deadly injury causing about onethird of injuryrelated deaths onesixth are caused by suicide and onetenth are caused by homicide tens of millions of individuals require medical treatment for nonfatal injuries each year and injuries are responsible for about 10% of all years lived with disability men are twice as likely to be killed through injury than women in 2013 367000 children under the age of five died from injuries down from 766000 in 1990 classification systems\n",
            "the world health organization (who) developed the international classification of external causes of injury (iceci) under this system injuries are classified by mechanism of injury objects/substances producing injury place of occurrence activity when injured the role of human intent and additional modules these codes allow the identification of distributions of injuries in specific populations and case identification for more detailed research on causes and preventive effortsthe united states bureau of labor statistics developed the occupational injury and illness classification system (oiics) under this system injuries are classified by nature part of body affected source and secondary source and event or exposure the oiics was first published in 1992 and has been updated several times since the orchard sports injury and illness classification system (osiics) previously osics is used to classify injuries to enable research into specific sports injuriesthe injury severity score (iss) is a medical score to assess trauma severity it correlates with mortality morbidity and hospitalization time after trauma\n",
            "Original Text 2: electrical injuries in the home are often minor while high tension power cables cause serious electrical injuries in the workplace lightning strikes can also cause severe electrical injuries fatal electrical injuries are often caused by tetanic spasm inducing respiratory arrest or interference with the heart causing cardiac arrestchemical burns are caused by contact with corrosive substances such as acid or alkali chemical burns are rarer than most other burns though there are many chemicals that can damage tissue the most common chemicalrelated injuries are those caused by carbon monoxide ammonia chlorine hydrochloric acid and sulfuric acid some chemical weapons induce chemical burns such as white phosphorus most chemical burns are treated with extensive application of water to remove the chemical contaminant though some burninducing chemicals react with water to create more severe injuries the ingestion of corrosive substances can cause chemical burns to the larynx and stomach other mechanisms\n",
            "toxic injury is caused by the ingestion inhalation injection or absorption of a toxin this may occur through an interaction caused by a drug or the ingestion of a poison different toxins may cause different types of injuries and many will cause injury to specific organs toxins in gases dusts aerosols and smoke can be inhaled potentially causing respiratory failure respiratory toxins can be released by structural fires industrial accidents domestic mishaps or through chemical weapons some toxicants may affect other parts of the body after inhalation such as carbon monoxideasphyxia causes injury to the body from a lack of oxygen\n",
            "Masked Text 1: traffic accidents are the most common form [MASK] [MASK] injury causing about onethird of injuryrelated deaths onesixth are caused by suicide and onetenth are caused by homicide tens of millions of [MASK] require medical treatment for nonfatal injuries each year [MASK] injuries are [MASK] for [MASK] 10% of all years lived [MASK] disability men are twice as likely to be killed through injury than women in 2013 367000 children under the age of five died from injuries down from 766000 in 1990 classification systems the world [MASK] organization ( [MASK] ) developed the international [MASK] of external causes of injury ( [MASK] ) under this system injuries are classified by mechanism of injury objects/substances producing injury place of occurrence activity when [MASK] the role of human intent and additional modules these codes allow the [MASK] of distributions of injuries [MASK] specific populations [MASK] case identification for more detailed research on causes and preventive effortsthe united states bureau of labor statistics developed the occupational injury and [MASK] classification system ( oiics ) under this system injuries are classified [MASK] nature part [MASK] [MASK] affected source and secondary [MASK] and event or exposure the oiics was first published in [MASK] and has been [MASK] several times since the orchard sports injury and illness classification system ( osiics ) [MASK] [MASK] is used to classify [MASK] to enable research into [MASK] sports injuriesthe injury severity score ( iss ) is a medical score to assess trauma severity it correlates with [MASK] morbidity and hospitalization [MASK] after trauma\n",
            "Masked Text 2: electrical injuries in the home are often minor while high tension power cables cause [MASK] electrical injuries in the workplace [MASK] strikes [MASK] also [MASK] [MASK] electrical injuries fatal [MASK] [MASK] are often caused by tetanic [MASK] inducing [MASK] arrest or interference [MASK] [MASK] heart [MASK] cardiac [MASK] burns are caused by contact with corrosive substances [MASK] as acid [MASK] alkali [MASK] burns are rarer than [MASK] other [MASK] though [MASK] are many chemicals that [MASK] damage [MASK] the [MASK] common [MASK] injuries are those caused by [MASK] monoxide ammonia [MASK] [MASK] acid [MASK] sulfuric acid some [MASK] weapons induce chemical burns such as white [MASK] most [MASK] burns are [MASK] with extensive application [MASK] water to [MASK] the [MASK] contaminant though some burninducing chemicals react with water to create more severe injuries the ingestion of [MASK] substances can cause chemical burns to the larynx and [MASK] other [MASK] toxic injury [MASK] caused by the ingestion inhalation injection [MASK] absorption [MASK] a toxin this may occur through [MASK] interaction caused [MASK] a drug [MASK] [MASK] ingestion of a poison different toxins may cause different [MASK] of injuries and many will cause injury to specific organs toxins [MASK] gases dusts aerosols and smoke can be inhaled potentially causing respiratory failure respiratory toxins can be released by structural fires industrial accidents domestic mishaps or [MASK] chemical [MASK] some [MASK] may affect other [MASK] of the body after inhalation [MASK] as carbon monoxideasphyxia causes injury to the body [MASK] a lack of oxygen\n",
            "Are sentences next? Yes (Original)\n",
            "Predicted NSP: No\n",
            "NSP Score: 0.6710 (Confidence)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import random\n",
        "\n",
        "# Assuming 'model', 'tokenizer', 'vocab', 'device' are correctly defined\n",
        "\n",
        "# Function to mask tokens\n",
        "def mask_tokens(tokens, vocab, probability=0.15):\n",
        "    masked_tokens = []\n",
        "    masked_positions = []\n",
        "    for i, token in enumerate(tokens):\n",
        "        if random.random() < probability:\n",
        "            masked_tokens.append('[MASK]')\n",
        "            masked_positions.append(i)\n",
        "        else:\n",
        "            masked_tokens.append(token)\n",
        "    return masked_tokens, masked_positions\n",
        "\n",
        "# Randomly select an example from the test dataset\n",
        "random_idx = random.randint(0, len(transformed_dataset['test']) - 1)\n",
        "input_example = transformed_dataset['test'][random_idx]\n",
        "\n",
        "# Tokenize the texts\n",
        "text1_tokens = tokenizer(input_example['text1'])\n",
        "text2_tokens = tokenizer(input_example['text2'])\n",
        "\n",
        "# Mask tokens\n",
        "masked_text1_tokens, _ = mask_tokens(text1_tokens, vocab)\n",
        "masked_text2_tokens, _ = mask_tokens(text2_tokens, vocab)\n",
        "\n",
        "# Convert tokens to indices, handling unknown tokens\n",
        "tokens_a_idx = [vocab[token] if token in vocab else vocab['[UNK]'] for token in masked_text1_tokens]\n",
        "tokens_b_idx = [vocab[token] if token in vocab else vocab['[UNK]'] for token in masked_text2_tokens]\n",
        "\n",
        "# Prepare inputs\n",
        "input_ids = [vocab['[CLS]']] + tokens_a_idx + [vocab['[SEP]']] + tokens_b_idx + [vocab['[SEP]']]\n",
        "segment_ids = [0] * (len(tokens_a_idx) + 2) + [1] * (len(tokens_b_idx) + 1)\n",
        "input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
        "segment_ids = torch.tensor(segment_ids).unsqueeze(0).to(device)\n",
        "\n",
        "# Inference\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    _, logits_nsp = model(input_ids, segment_ids, torch.tensor([]).unsqueeze(0).to(device))\n",
        "\n",
        "# Display results\n",
        "print(\"Original Text 1:\", input_example['text1'])\n",
        "print(\"Original Text 2:\", input_example['text2'])\n",
        "print(\"Masked Text 1:\", ' '.join(masked_text1_tokens))\n",
        "print(\"Masked Text 2:\", ' '.join(masked_text2_tokens))\n",
        "predicted_isNext = logits_nsp.argmax(dim=-1).item()\n",
        "confidence_score = torch.nn.functional.softmax(logits_nsp, dim=-1).max().item()\n",
        "predicted_isNext_text = \"Yes\" if predicted_isNext else \"No\"\n",
        "original_isNext_text = \"Yes\" if input_example['isNext'] else \"No\"\n",
        "print(f\"Are sentences next? {original_isNext_text} (Original)\")\n",
        "print(f\"Predicted NSP: {predicted_isNext_text}\")\n",
        "print(f\"NSP Score: {confidence_score:.4f} (Confidence)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 258,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original Text 1:\n",
            " these and other novel genes (dpti dptj) are believed to be involved in supplying the nonproteinogenic amino acids l3methylglutamic acid and kyn; they are located next to the nrps genesthe decanoic acid portion of daptomycin is synthesized by fatty acid synthase machinery (figure 2) posttranslational modification of the apoacyl carrier protein (acp thiolation or t domain) by a phosphopantetheinyltransferase (pptase) enzyme catalyzes the transfer of a flexible phosphopantetheine arm from coenzyme a to a conserved serine in the acp domain through a phosphodiester linkage the holoacp can provide a thiol on which the substrate and acyl chains are covalently bound during chain elongations the two core catalytic domains are an acyltransferase (at) and a ketosynthase (ks) the at acts upon a malonylcoa substrate and transfers an acyl group to the thiol of the acp domain this net transthiolation is an energyneutral step next the acylsacp gets transthiolated to a conserved cysteine on the ks; the ks decarboxylates the downstream malonylsacp and forms a βketoacylsacp this serves as the substrate for the next cycle of elongation before the next cycle begins however the βketo group undergoes reduction to the corresponding alcohol catalyzed by a ketoreductase domain followed by dehydration to the olefin catalyzed by a dehydratase domain and finally reduction to the methylene catalyzed by an enoylreductase domain each ks catalytic cycle results in the net addition of two carbons\n",
            "\n",
            "Original Text 2:\n",
            " the domain organization in such modules is catethe first module has a threedomain cat organization; these often occur in assembly lines that make nacylated peptides the first c domain catalyzes nacylation of the initiating amino acid (tryptophan) while it is installed on t  an adenylating enzyme (ad) catalyzes the condensation of decanoic acid and the nterminal tryptophan which incorporates decanoic acid into the growing peptide (figure 3) the genes responsible for this coupling event are dpte and dptf which are located upstream of dpta the first gene of the daptomycin nrps biosynthetic gene cluster once the coupling of decanoic acid to the nterminal tryptophan residue occurs the condensation of amino acids begins catalyzed by the nrpsthe first five modules of the nrps are encoded by the dpta gene and catalyze the condensation of ltryptophan dasparagine laspartate lthreonine and glycine respectively (figure 4) modules 6–11 which catalyze the condensation of lornithine laspartate dalanine laspartate glycine and dserine are encoded for the dptbc gene (figure 5) dptd catalyzes the incorporation of two nonproteinogenic amino acids l3methylglutamic acid (mglu) and kyn which is only known thus far to daptomycin into the growing peptide (figure 6) elongation by these nrps modules ultimately leads to macrocyclization and release in which an αamino group namely threonine acts as an internal nucleophile during cyclization to yield the 10aminoacid ring (figure 6) the termination module in the nrps assembly line has a catte organization\n",
            "\n",
            "Are sentences next? Yes (Original)\n",
            "\n",
            "Predicted NSP: No\n",
            "\n",
            "NSP Score: 0.6538 (Confidence)\n"
          ]
        }
      ],
      "source": [
        "# Select a random sample from transformed_dataset['test']\n",
        "random_idx = randint(0, len(transformed_dataset['test']) - 1)\n",
        "input_example = transformed_dataset['test'][random_idx]\n",
        "\n",
        "\n",
        "# Assuming 'tokenizer', 'vocab', and 'device' are already defined and loaded\n",
        "\n",
        "# Tokenize the input texts\n",
        "text1_tokens = tokenizer(input_example['text1'])\n",
        "text2_tokens = tokenizer(input_example['text2'])\n",
        "\n",
        "\n",
        "# Convert tokens to vocab indices\n",
        "tokens_a_idx = [vocab[token] if token in vocab else vocab['[UNK]'] for token in text1_tokens]\n",
        "tokens_b_idx = [vocab[token] if token in vocab else vocab['[UNK]'] for token in text2_tokens]\n",
        "\n",
        "# Prepare model inputs\n",
        "input_ids = [vocab['[CLS]']] + tokens_a_idx + [vocab['[SEP]']] + tokens_b_idx + [vocab['[SEP]']]\n",
        "segment_ids = [0] * (len(tokens_a_idx) + 2) + [1] * (len(tokens_b_idx) + 1)\n",
        "input_ids = torch.tensor(input_ids).unsqueeze(0).to(device)\n",
        "segment_ids = torch.tensor(segment_ids).unsqueeze(0).to(device)\n",
        "masked_pos = torch.tensor([]).unsqueeze(0).to(device)  # No masked tokens in the inference example\n",
        "\n",
        "# Ensure model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    logits_lm, logits_nsp = model(input_ids, segment_ids, masked_pos)\n",
        "\n",
        "# Predicted isNext flag and confidence score\n",
        "predicted_isNext = logits_nsp.argmax(dim=-1).item()\n",
        "confidence_score = torch.nn.functional.softmax(logits_nsp, dim=-1).max().item()\n",
        "predicted_isNext_text = \"Yes\" if predicted_isNext else \"No\"\n",
        "original_isNext = \"Yes\" if input_example['isNext'] else \"No\"\n",
        "\n",
        "# Display results\n",
        "print(\"Original Text 1:\\n\", input_example['text1'])\n",
        "print(\"\\nOriginal Text 2:\\n\", input_example['text2'])\n",
        "print(f\"\\nAre sentences next? {original_isNext} (Original)\")\n",
        "print(f\"\\nPredicted NSP: {predicted_isNext_text}\")\n",
        "print(f\"\\nNSP Score: {confidence_score:.4f} (Confidence)\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
